Antecedentes de software para la gestión de fallas viales
=========================================================

Pavimento
---------

El pavimento de una calle o autopista, es una estructura compuesta de un conjunto de capas de materiales procesados sobre el suelo, cuya función consiste en distribuir las cargas de los vehículos al sub-suelo y permitir el tránsito de los mismos. La estructura del pavimento debería proveer una superficie de calidad aceptable para la circulación de vehículos, resistencia adecuada al resbalamiento,reducir la contaminación de ruido producto de la circulación de los vehículos, una superficie impermeable, de manera que el suelo que esta debajo de las capas de material este bien protegido, resistencia estructural (con el fin de soportar todo tipo de fuerza aplicada sobre él) y un diseño con un ciclo de vida prolongado y bajo costo de mantenimiento.

Los pavimentos se pueden clasificar en dos tipos diferentes:

* Pavimento de rígido: Es una estructura compuesta por losas de hormigón cuya resistencia a la flexión es relativamente elevada.
Los pavimentos rígidos se integran por una losa de concreto de cemento portland, que se encuentra situada por encima de una capa base de grava, y ésta a la vez descansa en una capa de suelo compactado, denominada subrasante.


.. figure:: pav-rigido.png
   :scale:	80 %

	Estructura del pavimento rígido


* Pavimento flexible: Es una estructura compuesta por capas donde uno de los materiales presentes es el asfalto, lo que permite la deflexión (la deformación que del material como producto de una fuerza externa) bajo las cargas.
Los pavimentos flexibles se componen de una capa de mezcla asfáltica u hormigón asfáltico, que consiste en un agregado de asfalto y materiales minerales (como áridos) compactados y extendidos. ;Ésta se expone a las condiciones más severas debido al clima y tráfico, una capa base que se compone de materiales áridos (conjunto de materiales obtenidos de la fragmentación de rocas y arenas, tales como la grava, la gravilla y la arena), una capa de sub-base con materiales de calidad inferior a los empleados en la capa base.

.. figure:: pav-flexible.png
   :scale:	80 %

	Estructura de pavimento flexible



Tipos de juntas
---------------

Los senderos viales, tales como calles, autopistas, se encuentran sometidos a diversos cambios de temperatura durante el día, a diferencias de temperatura considerables entre las distintas estaciones del año, a cambios de humedad constante, y durante su construcción, a los tiempos de parada debido a las jornadas de trabajo con horas fijas, provocan que el material sufra dilataciones y contracciones y, si este material se encuentra extendido en una porción considerable de terreno, se producirá el agrietamiento aleatorio e irregular del mismo, a corto plazo. Para evitar ésto, se emplean juntas en el pavimento,como mecanismo de control de fisuras, que consisten en cortes realizada con maquinaria especial a lo largo y ancho del material, a una profundidad establecida según las propiedades de éste y de la calle, que lo divide en losas. Estas divisiones, se realizan a una distancia aproximada a la que aparecerían las fisuras, ya que en caso contrario, se fisurarían aquellas losas con dimensiones excesivas.

En base a la posición de las juntas respecto del avance del hormigonado, las juntas en el pavimento se pueden clasificar en juntas longitudinales, que son aquellas paralelas a dicho avance, o juntas transversales, que son aquellas perpendiculares según el avance del mismo. Por otro lado, las juntas se pueden clasificar respecto del tipo de función que cumplen como:

* Juntas de contracción: Pueden ser juntas tanto transversales como longitudinales, y su fin es limitar el tamaño de las losas, disminuyendo hasta valores aceptables, el nivel de tensión producida por fenómenos de retracción como por la variación de temperatura por distancia(gradiente térmico), de manera de evitar roturas en el material.
   
* Juntas de construcción: Son las juntas que se producen entre bandas del pavimento, o también en una misma banda, entre losas que se encuentran de manera contigua que se construyen con un tiempo de parada prolongado.

* Juntas de dilatación: Son las juntas que se realizan con el fin de absorber las expansiones del material como consecuencia de los aumentos de temperatura, evitando empujes sobre éste que podrían producir la rotura del mismo. En este tipo de junta,se emplea un material compresible (madera, poliestireno expandido, laminas de poliuretano,etc.) entre las losas con contacto, o entre la losa y otros elementos, como muros y arquetas. 
  
  
Tipos de fallas sobre pavimentos rígidos y flexibles
----------------------------------------------------

Fallas sobre pavimentos rígidos
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Dentro de los tipos de fallas que pueden ocurrir en pavimentos rígidos se encuentran los siguientes:

* Deficiencia de sellado: Este tipo de falla se ocasiona cuando se deterioran el sello de las juntas, por ejemplo, cuando existe fluencia fuera de la caja, despegado de ambas paredes, incrustación de materiales ajenos. El método de reparación de este tipo de falla consiste en realizar un sellado de juntas y de las grietas.

.. figure:: pav-rigido-deficiencia-sellado.png
   :scale: 70 %

   Deficiencia de sellado

* Losas desniveladas:  Ocurre cuando se desintegran las aristas de una junta, ya sea de manera longitudinal o transversal, con pérdida de trozos. Para este tipo de falla el método de reparación consiste en un sellado de juntas y grietas, o reparación de espesor parcial, que consiste en reponer las saltaduras de material superficial en juntas y grietas.

.. figure:: pav-rigido-losas-desniveladas.png
   :scale: 30 %

   Losas desniveladas

* Grietas: Una grieta se define como una abertura larga y estrecha en una losa de material, y ésta dependiendo de su ubicación en la losa, puede ser una grieta de esquina, longitudinal (si se extiende a lo largo de una losa) o transversal (si se extiende de manera perpendicular al volcado del material de la losa). El método de reparación para este tipo de falla, consiste en el sellado de juntas y grietas, y la reparación en todo el espesor. 
  
.. figure:: pav-rigido-grieta-longitudinal.png
   :scale: 50 %

   Grieta longitudinal


* Desintegración: Esta falla se produce cuando ocurre un desgaste progresivo de la superficie, dejando al material árido expuesto. El método de reparación de este tipo de falla, consiste en realizar una reparación de espesor parcial, en la que se corta la porción de la zona a reparar con una profundidad de corte preestablecida, se limpia la zona y se rellena la zona con un material especial de sellado de juntas.

.. figure:: pav-rigido-desintegracion.png
   :scale: 50 %

   Desintegración




* Baches: Un bache se define como una cabidad, generalmente de forma redondeada producto de la pérdida o hundimiento del pavimento en una parte de la superficie. El método de reparación para este tipo de falla depende del deterioro del mismo, y es especial para cada caso.
  
.. figure:: pav-rigido-bache.png
   :scale: 40 %

   Bache


* Levantamiento: Es el levantamiento de una porción de la losa, localizado en ambos lados de una junta transversal o grieta.El método de reparación consiste en realizar una reparación en todo el espesor, en la que se remueve y reemplaza una porción de la losa en todo su espesor, con el fin de reparar aquellas partes de la losa con un alto grado de daño.
|
   
.. figure:: pav-rigido-levantamiento.png
   :scale: 50 %

   Levantamiento de juntas

* Escalonamiento de juntas o grietas: Este tipo de falla ocurre cuando existe un desnivel entre dos superficies del pavimento, separadas por una junta transversal o grieta. El método de reparación para este tipo de falla es el fresado de la superficie, donde se separan las partes defectuosas del pavimento, de las que se encuentran en buen estado.
  
.. figure:: pav-rigido-escalonamiento-juntas.png
   :scale: 70 %

   Escalonamiento de juntas


* Descenso de banquinas: Es la diferencia de alturas que existe entre el borde del pavimento y la banquina. El método de reparación de este tipo de falla, consiste en realizar el nivelamiento de las banquinas no revestidas.

.. figure:: pav-rigido-descenso-banquinas.png
   :scale: 40 %

   Descenso de banquinas

.. raw:: latex
	
	\newpage

* Separación banquina-pavimento: Consiste en una rajadura entre el borde del pavimento y la banquina del sendero vial.El método de reparación consiste en realizar un sellado de juntas y grietas.

.. figure:: pav-rigido-separacion-banquina-pavimento.png
   :scale: 50 %

   Separación banquina-pavimento


* Parches deteriorados: Este tipo de falla surge cuando una porción de la superficie del asfalto ha sido removido y reemplazado por otro (como hormigón o asfalto), y ésta se ha dañado. El método de reparación de este tipo de falla, varía según el deterioro, y requiere una reparación especial.

.. figure:: pav-rigido-parche-deteriorado.png
   :scale: 40 %

   Parches deteriorados

Fallas sobre pavimentos flexibles
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

* Exudación: Este tipo de falla se presenta cuando el asfalto pierde sus agregados pétreos en la superficie. El tipo de reparación para esta falla consiste en enarenar y realizar una reparación superficial.

.. figure:: pav-flexible-exudacion.png
   :scale: 50 %

   Exudación


* Ahuellamiento y depresiones: El ahuellamiento es producido por el hundimiento de manera longitudinal del pavimento, y éste coincide con el área donde la mayor parte de los vehículos circula. Mientras que depresión, se considera un ahuellamiento de longitud menor al del ahuellamiento.
Si la profundidad máxima del ahuellamiento es inferior a los 20 mm, se realiza perfilado del pavimento, si la profundidad máxima es mayor a 20 mm pero inferior a 40 mm se realiza relleno de la rodadera, y si ésta es superior a 40 mm, se realiza una reparación local del pavimento.

.. raw:: latex
	
	\newpage

.. figure:: pav-flexible-ahuellamiento.png
   :scale: 50 %

   Ahuellamiento y depresión


* Grietas: Este tipo de falla tiene las mismas características que para pavimento rígido.

  
* Hundimiento del borde y ahuellamiento: Ocurre cuando se hunde el borde del material que limita con el margen.El método de reparación depende de la profundidad máxima del mismo, si ésta es menor a 20 mm se emplea perfilado del pavimento, si es superior a 20 mm pero inferior a 40 mm se emplea la técnica de relleno de rodadera, si es mayor a 40 mm se realiza una reparación local de la estructura del pavimento.

.. figure:: pav-flexible-ahuellamiento-borde.png
   :scale: 50 %

   Hundimiento del borde y ahuellamiento


* Baches: Este tipo de falla produce un hundimiento local del sendero vial, con agrietamiento  en malla cerrada y generalmente pérdida parcial de bloques de la capa de rodadura.Las técnicas de reparación de este tipo de falla consisten en restauración local de la estructura del pavimento, o bacheo sobre la base.
  
.. figure:: pav-flexible-baches.png
   :scale: 50 %

   Baches

.. raw:: latex
	
	\newpage

* Pérdida local de áridos: Este tipo de falla se presenta cuando ocurre una pérdida de una porción de la capa superficial. El método de reparación para este tipo de falla consiste en reemplazar el material afirmado.

.. figure:: pav-flexible-perdida-aridos.png
   :scale: 50 %

   Pérdida local de áridos


* Pulimiento o peladuras: Produce desprendimientos de la última capa de tratamientos superficiales. El método de reparación varía según la severidad, siendo un método de tratamiento superficial simple con una profundidad menor a 25 mm y área menor a 0,8 m2, y siendo nivelación con sobrecarpeta para profundidad o área mayores a 25 mm y 0,8 m2 respectivamente.

.. figure:: pav-flexible-pulimiento.png
   :scale: 50 %

   Pulimiento o peladuras


* Deformación: Se visualiza en pavimentos donde se produce una desviación longitudinal del material con respecto a su perfil original (asentamientos en el pavimento). El método de reparación con profundidad de la flecha de 13 a 25 mm o entre 25 mm y 50 mm es tratamiento superficial con medida preventiva, mientras que si se superan los 50 mm, se emplea bacheo seguido por aplicación de tratamiento superficial.
  
.. raw:: latex
	
	\newpage

.. figure:: pav-flexible-deformacion.png
   :scale: 50 %

   Deformación


Proyectos de software anteriores para la detección de fallas sobre el pavimento
-------------------------------------------------------------------------------

Debido a que la recolección manual de fallas es una tarea costosa con respecto al tiempo y al esfuerzo, durante años se  han publicado varios papers y tesis con el fin de automatizar esta tarea, a través del uso de distintos dispositivos para el sensado, combinados con distintas técnicas de localización, registro de fallas y análisis de la información sensada. Los papers y tesis publicados hasta la fecha se pueden clasificar según el tipo de sensor que emplean, en tres grandes grupos:

* Detección de fallas utilizando técnicas basadas en procesamiento de video/imagen
* Detección de fallas por medio de sensores de vibración(acelerómetro)
* Detección de fallas empleando reconstrucción 3D


Proyectos basados en procesamiento de video e imagen
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Conceptos de procesamiento de imágenes
""""""""""""""""""""""""""""""""""""""

Digitalización de imágenes
++++++++++++++++++++++++++

El mundo percibido diariamente por las personas se manifiesta en una variedad de formas, colores y texturas que la visión humana puede adquirir, integrar e interpretar con relativa facilidad, como así también, reconocer éstas en sus representaciones asociadas en textos, presentaciones multimedia, imágenes o video digital. No obstante, existe una gran cantidad de radiación que puede ser sensada, que se encuentra delimitada por el espectro electromagnético, descubierto por Sir Isaac Newton en 1666, cuando un rayo de luz atravesó un a través de un prisma, y Newton observó que el haz de luz es blanco, sino que se compone de un espectro continuo de colores desde violeta en un extremo (0.43 micrometros) hasta rojo en el otro(0.79 micrometros). 


|
.. figure:: espectroElectromagnetico.png
   :scale:	80 %

	El espectro electromagnético dividido y ampliado.
|

Como se puede observar en la figura anterior, en un extremo del espectro se encuentran las ondas de radio que se caracterizan por poseer longitudes de onda millones de veces mas largas a las de la luz visible, mientras que en el otro extremo se encuentran los rayos gamma con longitudes de onda millones de veces más pequeñas. El espectro electromagnético se puede expresar en función de la energía, la frecuencia o la longitud de onda (wavelength, LAMBDA). La longitud de onda (LAMBDA) y la frecuencia se encuentran relacionadas por la expresión:
|
LAMBDA = c/v

donde c es la velocidad de la luz (2.988 x 10 ^8 m/s). Por otro lado, la energía de varios componentes del espectro electromagnético se define en la expresión:
|
E = h*v(eq1)

donde h es la constante de Planck. Las unidades de las longitudes de onda se miden en metros, empleándose las medidas micrometros y nanómetros frecuentemente. La frecuencia se mide en Hertz(Hz), con 1 Hertz siendo igual a un ciclo de onda sinusoidal por segundo. Una unidad de medida para la energía en el espectro electromagnético es el electron-volt.

Por lo tanto, las ondas electromagnéticas pueden ser vistas como ondas sinusoidales con longitud de onda LAMBDA, o pueden ser consideradas como un flujo de partículas sin masa, cada una viajando en un patrón con forma de onda y moviéndose a la velocidad de la luz. Cada partícula sin masa, contiene una cierta cantidad de energía denominada fotón(photon). De la ecuación eq1 , se puede observar que la energía es proporcional a la frecuencia, por lo que cuanto más alta sea la frecuencia el fenómeno electromagnético llevará mas energía por fotón. Así las ondas de radio tienen fotones con baja energía, las microondas tienen más energía que las ondas de radio, las infrarojas aún más, siendo la luz visible, luz ultravioleta,los rayos X y finalmente los rayos gamma los que tienen mayor cantidad de energía de todos. Esta es la razón por la cual los rayos gamma son los más dañinos para los organismos vivientes.

|

.. figure:: ondaSinusoidal.png
   :scale:	80 %

	Representación gráfica de la longitud de onda (LAMDA)


Sin embargo, el ojo humano sólo puede capturar la luz visible de la radiación electromagnética, que representa una porción mínima de la radiación que puede ser percibida, y aunque esta banda es óptima ya que el volumen de información se encuentra reducido, es altamente confiable y disponible (ya que se encuentra fuertemente proyectada por el Sol y la atmósfera de la tierra es lo suficientemente transparente como para percibirla), la radiación de otras bandas puede ser igualmente útil para ciertas ramas de la ciencia, que graban y hacen uso de casi todo el espectro y emplean esta información con el objetivo de obtener un mejor concepto de la realidad física. Un ejemplo de esto son las ondas de sonido de alta frecuencia o ultrasonido, que son usadas para crear imágenes del cuerpo humano mientras que las imágenes de baja frecuencia son empleadas por compañías, para crear imágenes de la superficie de la tierra. Aunque la captura de imágenes se basa principalmente en la energía generadas por las ondas electromagnéticas, existen otros métodos para la generación de imágenes, tales como capturar el sonido reflejado desde un objeto con el fin de obtener imágenes ultrasónicas, o rayos de electrones como los que emplean los microscopios de electrones para obtener imágenes que permitan recolectar información respecto de especímenes biológicos e inorgánicos, incluyendo microorganismos, muestras de biopsias, metales y cristales. 

Las imágenes,aunque tengan distintas fuentes, comparten el hecho de que existe una radiación que es emitida desde alguna fuente para posteriormente interactuar con algún tipo de material, luego es sensada y trasladada en una señal eléctrica que puede ser digitalizada. Las imágenes se pueden clasificar según la forma en la que la interacción con el dispositivo de sensado ocurre en 3 categorías generales:

* Las imágenes de reflexión son aquellas en que la radiación ha sido reflejada desde la superficie de un objeto. Ésta puede ser del ambiente o artificial, y puede provenir desde una fuente localizada o desde fuentes múltiples. Este tipo de imágenes son las que se perciben día a día por las personas por medio de la vista, mientras que algunos ejemplos de imágenes no visibles de este tipo incluyen imágenes por radar, imágenes por sonar y algunos tipos de imágenes por microscopio. El tipo de información que puede ser extraída desde este tipo de imagen es generalmente respecto de la superficie de los objetos, su forma, color, textura y reflectividad.
* Las imágenes de emisión son aquellas cuya radiación es emitida por el objeto que se desea capturar, como las imágenes térmicas o infrarojas, y que son usadas por áreas como la medicina, pruebas militares, o en objetos luminosos como bombillas de luz, estrellas, imágenes de resonancia magnética (MRI), las cuales obtienen información en base a la capacidad de emisión de las partículas. Cuando se emplea este tipo de imágenes se desea obtener información respecto de la estructura interna del objeto, aunque también pueden ser empleadas para información externa, por ejemplo, una cámara térmica utilizada en situaciones con baja iluminación, con el fin de producir una imagen que capture los objetos que producen calor en una escena.
* Las imágenes de absorción donde la radiación atraviesa el material que compone el objeto y es absorbida o atenuada por éste parcialmente, lo que proporciona información relacionada con la estructura interna del mismo. El grado de absorción determina el nivel de la imagen registrada. Ejemplos de este tipo de imágenes son los rayos X, imágenes de transmisión microscópicas y ciertos tipos de imágenes sónicas.   
|

.. figure:: tiposInteraccionImagenes.png
   :scale:	80 %

	Tipos de interacción para el sensado de imágenes


Para que un sensor pueda captar un objeto de determinado tamaño, es necesario que la longitud de onda del sensor sea igual o menor al tamaño de del objeto, por lo que este requerimiento junto con el material del sensor, establecen los límites de la capacidad de captura del sensor de imagen y su clasificación en distintos tipos, tales como sensores infrarojos, de luz visible,etc. Así, con el fin de capturar imágenes digitales en las distintas bandas del espectro electromagnético, es necesario emplear sensores que puedan captar la energía irradiada en cierto rango y produzcan una señal eléctrica de salida (generada por una combinación entre el material sensible a la radiación del sensor y la fuente de alimentación del mismo), que permita la representación de una imagen del mundo tridimensional de interés en formato digital.


.. figure:: sensorCaptura.png
   :scale: 90%
   
	Sensor individual de captura


Cuando un fenómeno es captado por un dispositivo con uno o varios sensores, estos en general producen una onda de voltaje continua cuya amplitud y forma esta relacionada a la radiación emitida o reflejada desde el objeto, por lo que para crear una imagen digital, es necesario realizar una conversión estos datos en un formato digital, dando como resultado una imagen digital. Este proceso comienza con la conversión de las coordenadas espaciales de la imagen a una matriz multidimensional que pueda ser indexada por valores numéricos(también llamado proceso de muestreo o sampling), de esta forma la señal puede ser almacenada y procesada como un arreglo de M filas x N columnas de valores discretos, donde cada uno de los elementos (i,j) que pueden ser indexados en la matriz se denomina elemento de imagen(picture element), pel o pixel. Así si una imagen digital contiene M x N pixeles, se representa por una matriz de M x N elementos conteniendo desde 0 hasta M-1 índices en las filas y desde 0 hasta N-1 índices en las columnas.
Cuando la cantidad de pixeles muestreados no es suficiente(undersampling) como para representar la imagen, se produce un efecto denominado aliasing, que produce que la imagen visual pierda el patrón de la imagen original que intenta representar, produciendo una falso patrón y una imagen distorcionada. Como se observa en la siguiente imagen de una huella digital, a medida que la densidad de pixeles muestreados disminuye, la calidad de la imagen empeora y se produce éste efecto:


.. figure:: aliasing.png
   :scale: 80%
   
	Efecto de aliasing. 256x256 (2^8*2^8=65,536 muestras). 128x128(2^7*2^7=16,384 muestras).64x64(2^6*2^6=4,096 muestras)
|

.. figure:: imagenPixels.png

	Representación de un array de imagen de 10 x 10

.. NOTA: VER SI AGREGAR ACA LAS PROPIEDADES DE LOS PIXELES. PAG 83.Pretince Hall Gonzales 2 ed.


El siguiente paso consiste en realizar la cuantificación o quantization, donde se realiza la conversión de las intensidades analógicas captadas por los sensores a valores numéricos discretos, asignando un valor a cada pixel muestreado, de manera que la imagen reconstruida de los valores muestreados sean de una calidad lo más aproximada a la real y el error introducido por la cuantificación sea mínimo.
Con el fin de cuantificar, el rango de valores dinámicos que puede adoptar los pixeles de una imagen se dividide en un rango finito de intervalos, y a cada intervalo se le asigna un valor.Cuanto mayores sean los intervalos disponibles para cuantificación, la imagen digitalizada se aproximará con más fidelidad a la imagen real. 
La cuantificación se puede realizar de manera uniforme, cuando los valores de intensidad tienen mayor probabilidad de caer en intervalos regulares y se opta por dividir el rango de niveles en intervalos igualmente espaciados. Por otro lado, cuando la imagen adopta valores en un rango con una frecuencia prolongada y otros valores de manera infrecuente, es preferible emplear la cuantificación no uniforme. 




.. figure:: cuantificacionUniformeNoUniforme.png
   :scale: 70%

	Cuantificación de imagen de 2 dimensiones.Cuantificación uniforme (a).Cuantificación no uniforme (b).


De esta forma, el proceso de digitalización requiere los valores de M,N y la cantidad de niveles de intensidad L( niveles de gris en el caso de las imágenes con escala de grises o de valores en las bandas roja,verde y azul para las imágenes a color) como valores positivos, permitidos para cada pixel. No obstante, debido a las consideraciones de hardware, procesamiento y almacenamiento, el número de niveles es típicamente una potencia de 2:


.. math:: L = 2^k
	:label: formulaNivelIntensidad
.. .. math:: e^{i\pi} + 1 = 0
   :label: euler
.. Euler's identity, equation :eq:`euler`, was elected one of the most
.. beautiful mathematical formulas.


Donde k es el número de bits empleados para representar el nivel de cada pixel. En general, el número de bits k se encuentra entre 1<=k<=8, empleándose k=1 para imágenes binarias, k=8 para imágenes por escala de grises (donde cada nivel ocupa cun byte) y, para el caso de las imágenes a color, con múltiples valores, cada nivel de color ocupa 8 bits usando los colores rojo,verde y azul (RGB), empleándose 24 bits por pixel con el fin de representar el color de éste. 
Así, cuando una imagen puede tener 2^k niveles de gris, es una práctica común referirse a la imagen como una "imagen de k-bits".Por ejemplo, una imagen con 256 niveles posibles es llamada una imagen de 8 bits.Por lo tanto, la cantidad de bits requeridos para almacenar una imagen será:

.. math:: b = M x N x k
	:label: cantBitsNecesarios

.. figure:: resultadoDelProcesoCuantificacion.png

   Representación del proceso de muestreo y cuantificación.Imagen continua captada por un dispositivo de sensado(a).Imagen muestreada y cuantificada(b).




Relaciones entre pixeles
++++++++++++++++++++++++
.. CONTENIDOS A INCLUIR: 
..	-Relaciones entre pixeles y DISTANCIA ENTRE LOS MISMOS, background,foreground, region,interpolacion,neirbourhood o ventana, mascara.

Los pixeles Pk en la coordenada (i,j), con k siendo la cantidad total de pixeles con los indices i=1,2,...,n y j=1,2,...,m, que componen una imagen digital cuentan con distintas propiedades entre las que se encuentran las siguientes:

* Pixeles conectados: Un pixel en un punto P0 en (i0,j0) se conecta a otro pixel Pn en (in,jn) si y sólo si existe un camino desde P0 hasta Pn, que es una secuencia de puntos (i0,j0),(i1,j1)...(in,jn) tal que el pixel (ik,jk) es un vecino del pixel en (ik+1,jk+1) y Pk= Pk+1 para todos los k, 0 < k < n-1. La secuencia de pixeles distintos de un pixel a otro también se denomina camino digital (digital path) y, si el primer pixel del camino se encuentra conectado con el primer pixel, se denomina un camino cerrado.
  
* 4-vecinos(4-connected pixel): Cuando un pixel P en la ubicación (i,j) tiene cuatro vecinos en las coordenadas (i+1,j), (i-1,j), (i,j+1) e (i,j-1) se conocen como 4-vecinos.Es decir, que cada pixel esta a una unidad de distancia' de (i,j) y algunas de las ubicaciones de P yacen fuera de la imagen digital en el borde la imagen.


* 8-vecinos(8-connected pixel): Se dice que un pixel P ubicado en (i,j) tiene una conexión diagonal de 4 pixeles, cuando tiene pixeles en las coordenadas (i+1,j+1),(i+1,j-1),(i-1,j+1) e (i-1,j-1). Si además este pixel tiene 4-vecinos, se dice que estos pixeles son 8-vecinos de P. 


Otra propiedad de los pixeles es la adyacencia que se define en términos de los niveles de intensidad, siendo V el conjunto de valores de intensidad que un pixel puede adoptar, con V = {1} en imágenes binarias (considerandose adayacentes dos pixeles que tienen intensidad 1) y V siendo un subconjunto de todos los niveles de la imagen (para el caso de imagenes por escala de grises) y considerándose adyacentes dos pixeles cuyos valores de intensidad están en ese subconjunto. Existen 3 tipos de adyacencia:

* 4-adyacentes(4-adjacency). Dos pixeles P y Q con valores del conjunto V son 4-adyacentes si Q esta en el conjunto de los 4-vecinos de P.

* 8-adyacentes(8-adjacency).Dos pixeles P y Q con valores del conjunto V son 8-adyacentes si Q esta en el conjunto de los 8-vecinos de P.

* adyacencia mixta(m-adjacency o mixed-adjacency). Dos pixeles P0 y P1 con valores del conjunto V son m-adyacentes si: 

	* P0 es un 4-vecino de P1, o
	* Si P0 esta en una conexión diagonal de P1 y el conjunto de 4-vecinos de P0 y de P1 no tienen valores en común con el conjunto V de niveles.
 
* Componente conectado: Si dado un subconjunto de pixeles S en una imagen, dos pixeles P0 y P1 se dicen conectados si existe un camino digital que se compone de los pixeles en S.Así, para cualquier pixel P que este en S, el conjunto de pixeles que están conectados a él es llamado un componente conectado de S. Un conjunto de pixeles conectados (4 u 8 pixeles) forman un componente conectado,que representa un objeto en escena.

* Región. Dado un subconjunto de pixeles R en una imagen, R se denomina una región si es un componente conectado, y dos regiones R1 y R2 se dicen adyacentes si su unión forma un conjunto conectado, o disjuntas en caso contrario.


* Fondo(background) y Frente(foreground). Si una imagen contiene Rk regiones con k=1,2,...,N, la unión de todas las regiones se considera el frente, mientras que el resto de los pixeles que no esta en ninguna región se considera el complemento.

* Borde o Contorno(boundary,border,contour). El contorno de una región R es el conjunto de los puntos que son adyacentes a los puntos que no estan R(complemento), es decir, que éste se compone de aquellos pixeles en la región que tienen al menos un vecino que forma parte del fondo.Si R es una imagen entera(matriz de pixeles), entonces su contorno se define como el conjunto de pixeles en la primera y ultima fila y columna de la imagen, ya que una imagen no contiene más vecinos más alla de los bordes.

|

.. figure:: tiposConexionesImgBinaria.png
  
    Tipos de conexiones entre pixeles. 4-vecinos(a). 8-vecinos(b). Componente conectado y fondo(c).

Una vez que un objeto es identificado algunos de sus atributos se pueden definir de la siguiente manera:

* Área del objeto: El área de un objeto se da como la sumatoria de todos los pixeles i,j que forman el objeto(pixeles con valor 1).
* Ubicación del objeto: La ubicación del objeto se define como el centro del objeto en X e Y, calculados por medio de la sumatoria de las coordenadas del objeto dividido por el área del mismo. En la siguiente ecuación se puede observar la forma de calcular los centroides Xc e Yc:
|
|

.. figure:: calculoCentroide.png
   :scale: 80%
   
   Fórmula para el cálculo del objeto

* Orientación de un objeto: Cuando el objeto tiene una forma alargada, los ejes de la elongación producen la orientación del mismo.El eje de elongación es una línea recta tal que la suma de las distancias al cuadrado, de todos los puntos del objeto desde esta línea es mínimo(distancia perpendicular de un punto del objeto hacia la línea).
* Perímetro de un objeto: El perímetro de un objeto se obtiene sumando los pixeles que forman parte del límite del objeto y que son parte del área. El límite o contorno de un objeto esta formado por aquellos pixeles que tienen uno o más vecinos que no están en el área.

.. Nombres de conexiones en español --> http://scfi.uaemex.mx/hamontes/files/TI04%20-%20Relaciones%20basicas%20entre%20pixeles.pdf



Operaciones y técnicas sobre imágenes digitales
+++++++++++++++++++++++++++++++++++++++++++++++

.. COMANDO PARA CAMBIAR DIRECTORIO SCREENPRINT --> 
.. gsettings set org.gnome.gnome-screenshot auto-save-directory "file:///home/rodrigo/TESINA-2016-KINECT/DOCUMENTO_TESINA_FORMAL/tesinaInforme/"


..	-Tipos de operaciones que se realizan sobre una imagen (SUMA,RESTA,DIVISION,MULTIPLICACION y sus efectos a nivel de imagen, a nivel de pixel transformaciones espaciales),

.. -Dominio espacial:
..					- Operaciones de transformacion con pixeles, vecindarios(windows, o mask) e imagenes. Cap 3. Relacionado con 2 tipos de categorias de transformaciones: filtrado espacial(filtros de suavizado y sharpening) y transformaciones de intensidad.
.. 
.. -Dominio de transformaciones:
..					-Son metodos que se basan en transformar una imagen a un dominio de interes, procesarla en ese dominio y luego regresarla de vuelta al dominio inicial(imagen de salida). 
..					-Formula de Fourier y dominio de frecuencia, que son paralelos a las tecnicas descritas con el dominio espacial pero empleando las frecuencias de la imagen.
.. NOTA: Nivel h6 de identación.
.. NOTA:  FILTROS, E HISTOGRAMA DE FRECUENCIAS!!! 


De forma general, existen dos tipos de aproximaciones que pueden emplearse en una imagen para aplicar técnicas de mejora de imagen y transformación: Emplear técnicas que actúen dominio espacial de la imagen, es decir modificando ciertas características sobre los pixeles de la imagen directamente; O Emplear técnicas que se ejecutan sobre el dominio de frecuencias de la imagen, que consisten en realizar una conversión de los valores de la imagen para llevarla a otro dominio, ejecutar transformaciones sobre ese dominio y finalmente, realizar la transformación inversa para obtener la imagen de salida.      

Técnicas que sobre el dominio espacial
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Debido a que las imágenes se representan como matrices, es posible tanto aplicar operaciones aritméticas y lógicas entre matrices, como ejecutar operaciones que modifiquen características de los pixeles, con el fin de modificar ciertas características de éstas. Los tipos principales de operaciones que se pueden emplear se pueden clasificar en 3 tipos generales:

* Operaciones de manipulación de intensidad (modificación de pixeles individuales).
* Operaciones aritméticas entre matrices de la misma dimensión (estas operaciones incluyen suma,resta, multiplicación y división entre matrices).
* Operaciones geométricas de transformación (interpolación,traslación,rotación, filtrado espacial).


Operaciones de manipulación de intensidad
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

En este tipo de técnicas las operaciones se aplican a pixeles individuales, por lo que las relaciones entre pixeles vecinos no se consideran, como así tampoco la localización de los pixeles sino que se modifican las intensidades de los pixeles.
En esta sección, se describen algunas de las herramientas que se emplean para modificar los valores de intensidad de una imagen y su principal utilidad.


Histograma de imagen
####################
.. NOTA: Identacion h8

La herramienta básica para este tipo de operaciones es el histograma de imagen,que es una representación gráfica que agrupa las frecuencias de ocurrencias de cada nivel de intensidad (nivel de gris en imagenes por escala de grises) en los pixeles de la imagen. De esta manera, si se cuenta con K niveles de intensidad {0,1,...,K-1} y una cantidad NxM de pixeles, el histograma se define matemáticamente de la siguiente manera:

.. math:: Hf(k) = J
   :label: formulaHistogramaImagen


.. PAGINA 142 Image processing 3rd edition. Gonzales.

Donde f() es la función que mapea el nivel de intensidad a cada pixel P(x,y), y J representa la cantidad de ocurrencias de ese nivel en los pixeles, con K niveles.Aunque este tipo de histograma no contiene información espacial con respecto a la imagen, es una herramienta valiosa que permite visualizar si la distribución de niveles de intensidad en una imagen es correcta, o si la imagen tiene tonalidades mas oscuras o más claras. Por ejemplo, en un histograma que corresponde a una imagen con escala de grises los niveles más oscuros se concentran sobre la parte más baja de la escala del histograma, mientras que los niveles más brillantes están en la parte alta del diagrama. Así, una imagen por escala de grises con bajo contraste, tendrá un histograma cuyos puntos se encuentran centrados en la escala y abarcan pocos valores en el rango, mientras que si ésta tiene un contraste alto, los valores del histograma abarcarán un rango amplio de la escala y, su distribución tenderá a ser uniforme.



.. figure:: variosNivelesContraste.png
   :scale: 60%

   Imágenes con distintos niveles de contraste y sus histogramas asociados

En la siguiente figura se puede observar, que la figura de la izquierda presenta niveles de gris más oscuros, mientras que la figura de la derecha presenta niveles de grises con más brillo, lo que indica que han estado expuestas a condiciones de luz excesiva y escasa. 
|


.. figure:: histogramaImagen.png

   Histograma de imagen.
|

Algunas veces el histograma de imagen se normaliza, dividiendo la cantidad de ocurrencias en cada nivel de intensidad, por el número total de pixeles en la imagen(N*M), de manera que la sumatoria de los componentes de un histograma normalizado sea 1. 

El histograma de imagen es una herramienta básica empleada por varias técnicas de procesamiento de imágenes con intensidad como la mejora de imagen,además de proveer información de utilidad para la compresión y la segmentación de imágenes.  


Escalado de histograma
######################

El escalado de histograma consiste modificar el rango de niveles de intensidad que se consideran para representar un histograma.Este procedimiento dada una función f(n) que representa el histograma para cada uno de los n pixeles, consiste en multiplicar cada uno de estos valores por una constante numérica P (mayor o menor a 1):

.. math:: g(n) = P*f(n)
   :label: formulaEscaladoImagen

Por ejemplo si se emplea un histograma de una imagen de escala de grises, si el valor de la constante P > 1, los niveles de gris cubrirán un rango mas amplio que aquellos de la función del histograma f(), mientras que si P < 1 se empleará un rango de niveles de gris más reducido, lo que puede producir pérdida de información en la imagen y disminuir su nitidez.
| A continuación se pueden observar imágenes originales y los efectos de aplicar el histograma de imagen con dos escalas distintas:

.. figure:: efectoEscaladoHistograma.png
	:scale: 80%

	Efectos del escalado de histograma entre dos puntos A-B.

| 
.. figure:: estudiantesOriginal.png
	:scale: 70%

	Imagen de estudiantes original (izquierda) y su histograma de imagen asociado(derecha).

| 
.. figure:: estudiantesEscalaHistograma.png
	:scale: 70%

	Modificación de la escala del histograma con P=0,75, en este caso los niveles de gris de la imagen tienden a juntarse, provocando que la imagen disminuya su calidad.

| 
.. figure:: imagenOriginalLibros.png
	:scale: 70%

	Imagen de libros(izquierda) y su histograma(derecha)

| 
.. figure:: librosEscalaHistograma.png

   Modificación de la escala del histograma con P=2. En este caso, la expansión de los valores del histograma de imagen, produce que se haga un mejor uso de los niveles de gris, produciendo una mejora en la nitidez de la misma



Negativo de imagen
##################

El negativo de una imagen consiste en escalar éstos con P=-1 revirtiendo el signo de los valores y  sumar un desplazamiento a los valores de intensidad de cada pixel K-1 con el fin de que estos se encuentren en el rango del histograma:

.. math:: g(n) = -f(n) + (K-1)
	:label: formulaImgInversa
|
|

.. figure:: imagenNegativa.png

   Imagen negativa con su histograma modificado
|

Esta técnica se emplea para mejorar imágenes donde se pierde el nivel de detalle en las regiones con niveles blanco y negro, percibiéndose ésta como demasiado oscura. Un ejemplo de esta operación es la inspección de imágenes telescópicas con campos de estrellas y galaxias, donde con una imagen negativa los objetos brillantes, aparecen con una tonalidad oscura sobre un fondo brillante que es mas sencillo de apreciar.   

Igualación de histograma(Histogram Equalization)
################################################



Especificación(Histogram Matching o Specification)
##################################################

.. pag 150. Image processing 3rd edition Gonzales.



Shaping de histograma
#####################



Operaciones aritméticas entre matrices
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~




Operaciones geométricas de transformación
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Interpolación
#############

.. NOTA: Identacion h8

Una herramienta relacionada con las imágenes digitales es la interpolación, empleada en tareas como hacer zoom, reducción(shrinking), rotación y correcciones geométricas. Esta herramienta consiste en emplear datos conocidos de la imagen para estimar valores en coordenadas desconocidas. Por ejemplo, si se necesitara convertir una imagen a una escala mayor, la cantidad de pixeles y la correspondencia entre las intensidades diferirían por lo que sería necesario contar con un método que permita la asignación aproximada de intensidades. Un método para realizar ésto es asignar a cada pixel en la imagen mayor, el valor del pixel vecino más cercano si se superpone, esta imagen con la imagen de entrada, este metodo se conoce como interpolación de vecino más cercano.
Existen otros métodos para asignar intensidades que consideran más vecinos y, la forma en que consideran estos sigue alguna fórmula matemática, entre los que se encuentran la interpolación bilinear (donde se emplean los 4 vecinos mas cercanos para estimar la intensidad) y la interpolación bicubica (que toma los 16 vecinos más cercanos):

|

.. figure:: interpolacionBilinear.png
      
         Fórmula de interpolación bilinear
|
|

Donde v(x,y) es la intensidad del pixel en la coordenada(x,y), los coeficientes a,b,c y d se emplean para determinar los vecinos que de los que se obtendrá la intensidad. 


.. figure:: interpolacionBicubica.png
      
         Fórmula de interpolación bicubica
|



Técnicas sobre el dominio de las transformaciones
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

TRANSFORMADA DE FOURIER





Tipos de imágenes digitales
+++++++++++++++++++++++++++

Existen distintos tipos de imágenes digitales según la metodología seleccionada para representar la intensidad, entre los que se destacan los siguientes tipos: Imágenes binarias, imágenes por escalas de grises, imágenes a color e imágenes indexadas.



Imágenes por escala de grises
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Este tipo de imágenes se representa por medio de un conjunto de valores, que abarcan distintas tonalidades de grises desde blanco hasta negro, representándose cada pixel con 8 bits.
|

.. figure:: greyscaleImg.png
	:scale: 50%
   
	Representación de imagen en escala de grises


Existen distintos tipos de operaciones que pueden realizarse sobre imágenes con escalas de grises, aunque se pueden clasificar de manera general en: Operaciones de puntos, operaciones aritméticas y operaciones geométricas.
Las operaciones de puntos son aplicadas a los pixeles individuales de una imagen, por lo que las interacciones y las dependencias entre pixeles vecinos no son consideradas, ni las operaciones que toman un conjunto de pixeles, sino que se basan en el procesamiento de las intensidades de los pixeles. Por lo tanto, este tipo de operación no altera la posición de los objetos en la imagen, sino que modifican la apariencia general de la imagen, cambiando la distribución de grises de la misma ,obteniendo el negativo o, desplazando los niveles de grises para aclarar la imagen.


Las operaciones aritméticas se realizan entre imágenes de las mismas dimensiones espaciales, este tipo de operaciones es similar  a las operaciones por puntos debido a que la información espacial no es considerada, sino que la información se comparte entre imágenes y  se ejecutan pixel por pixel. Este tipo de operaciones se emplea para para la reducción del ruido en la imagen (distorciones aleatorias en la imagen producidas por radiación antes de capturar la misma o por fallos eléctricos en el dispositivo de sensado ), donde se realiza un promediado de las tonalidades de grises de un conjunto de frames y el resultado final es una imagen cuyo nivel de ruido ha sido reducido considerablemente.
Otra área donde se emplean operaciones de éste tipo es en la detección de movimiento en sistemas de vigilancia, o en sistemas automatizados de inspección visual, donde se realiza la diferencia entre las matrices que representan las imágenes y luego se computa el histograma de imagen, que mostrará variaciones importantes en el intensidad (valores de brillo mayores) si cambios significativos han ocurrido entre dos frames.

Finalmente, las operaciones geométricas que son operaciones complementarias a las operaciones por puntos debido a que no modifican los valores de los niveles de gris, sino que modifican la imagen modificando cambiando las posiciones de los elementos de la imagen. Este tipo de operaciones se emplea para realizar la rotación, traslación o zoom-in o zoom-out en la imagen.


Imágenes binarias
~~~~~~~~~~~~~~~~~

En este tipo de imagen digital la intensidad de los pixeles sólo puede asumir dos valores 0 o 1, por lo que sólo se requiere un bit para su representación, siendo estas imágenes las que requieren menos espacio y tiempo de almacenamiento. Estas imágenes contienen suficiente información respecto de los objetos en la imagen y permiten que éstos se reconozcan fácilmente.
Este tipo de imágenes se emplean en distintos tipos de aplicaciones de visión por computadora, como el reconocimiento de objetos, el rastreo,etc. aunque su aplicabilidad es limitada debido al contenido limitado de información que brindan.
Las imágenes binarias surgen de una variedad de fuentes, generalmente son creadas por medio del procesamiento de imágenes de escala de grises, aunque algunos tipos de sensores entregan una imagen binaria como salida, como los dispositivos que se emplean para obtener dibujos o texto escrito a mano con un pad resistivo, un lápiz de luz. Generalmente estos dispositivos, inicializan todas las coordenadas de la imagen binaria en cero, y al detectar la presión o un cambio de resistencia, o luz sensada en una coordenada, entonces se le asigna a la misma el valor 1.Ejemplos de imágenes binarias, son los dibujos de líneas, texto escrito o impreso, siluetas, huellas digitales,o planos empleados por arquitectos.
|

.. figure:: imagenBinaria.png

   Imagen binaria


Un objeto en una imagen binaria se considera como un conjunto de pixeles con nivel 1 conectados.Existen diversas técnicas que se emplean para el procesamiento de imágenes binarias, entre las que se encuentran:

* Delimitación de la imagen(Image thresholding). Esta técnica se emplea cuando se desea abstraer información desde una imagen con escala de grises, con el fin de obtener una imagen binaria, y consiste en definir un límite T de nivel de gris máximo que un pixel puede adoptar, y luego filtrar aquellos pixeles en la imagen (estableciéndolos a 1 en la imagen binaria), cuyo límite sea menor que el establecido. De esta forma, T permite controlar el nivel de detalle que la imagen resultante poseerá y, variando este límite se puede obtener una imagen que sea más eficiente para procesar, analizar o interpretar.
Sin embargo, éste método aplicado a imágenes cuyos histogramas de intensidad sean planos o que varios objetos con un brillo promedio diferente sobre un fondo uniforme, puede provocar que algunos objetos se dejen afuera de la imagen final. 
|

.. figure:: delimitacionImgBinaria.png
	:scale: 60%

	Situaciones donde la delimitación de imagen puede encontrar problema. Histograma multimodal(varios objetos de distintos promedios de brillo) (a). Histograma plano(b)

|
|
* Etiquetado de regiones(Region labeling). Esta es empleada para identificar y localizar objetos en una imagen y, posteriormente éstos pueden ser modificados, mostrados o manipulados por separado. Éste procedimiento busca encontrar regiones en la imagen a través de pixeles conectados con el mismo valor, escaneando la imagen desde el origen (posición superior izquierda) y buscando pixeles que tengan el mismo valor binario y estén conectados en las direcciones horizontales y verticales. Un registro de los grupos de pixeles encontrados se mantiene en un arreglo separado de labels, con las mismas dimensiones de la imagen. 

* Filtros de imágenes binarias. Existen diversos filtros que pueden emplearse con el fin de mejorar o cambiar la forma de los objetos en imagen binaria. Estos consisten en ventanas de pixeles, que son un conjunto de reglas que permiten definir la forma que un conjunto de pixeles adoptará y, así permiten delimitar que pixeles vecinos (con sus niveles de gris) serán empleados para la aplicación del filtro. Estas ventanas se emplean en combinación con operaciones lógicas AND,OR,NOT y XOR (delimitación de borde de imagen) y se desplazan a la lo largo de toda la imagen, modificando así el valor binario por medio de éstas operaciones lógicas. En general, ésto se realiza fila por fila, columna por columna aunque puede ser logrado procesando varios grupos a la vez, si se realiza de forma concurrente.
Las ventanas se definen por medio de una ecuación matemática, que permite definir formalmente la forma que tendrá, según se adopten distintas cantidad de pixeles. Por ejemplo, si se desea generar una columna la ecuación podría estar dada por: 2P + 1, generando una columna de 3 pixeles si P=1, o de 5 pixeles si P=2. 

|

.. figure:: ventanasImgBinaria.png
	:scale: 70%
   
	Tipos de ventanas.

Dependiendo del tipo de operación lógica que se aplique con la ventana, se logrará un efecto distinto en la imagen. Así, si se emplea la operación OR se producirá un efecto de dilatación de aquellos pixeles donde sus valores sean distintos o iguales, mientras que si se aplica la operación AND se producirá un efecto de erosión, donde aquellos pixeles vecinos que tengan un valor distinto al del pixel sobre el que esta la ventana, serán filtrados.



Imágenes a color
~~~~~~~~~~~~~~~~

Con la finalidad de incluir el color en el procesamiento de imágenes, se debe emplear un modelo de color que permita la especificación de las intensidades de los colores en un sistema de coordenadas y un rango de valores dentro de ese sistema de coordenadas, donde cada color sea representado por un único valor. Debido a la variedad de campos de aplicación del color, existen diferentes esquemas de representación según el objetivo, entre los que se encuentran:

* RGB(Red,Green,Blue). Emplea diversas combinaciones de colores primarios(normalizados entre [0,1] o sino valores en el rango 0-255) para la representación de colores en imágenes. Este modelo es utilizado principalmente por monitores a color y cámaras de video y para la manipulación y generación de imágenes digitales.
* CMY(Cyan,Magenta,Amarillo) y CMYK(Cyan,Magenta,Amarillo,Negro). Hace uso de los colores secundarios para representar el color, y es empleado para la impresión de imágenes color, realizándose una conversión interna del esquema RGB a CMY/K.
* HSI(Tonalidad,Saturación,Intensidad). La tonalidad es un valor que describe el nivel de pureza de un color (rojo,verde o azul) percibido por un observador, la saturación brinda una medida del grado en que la luz blanca esta mezclado con la tonalidad de un color y, el brillo es una medida subjetiva que abarca la noción de la intensidad en imágenes sin color.Este modelo hace uso de estas características y además permite desacoplar la información de color y el componente de intensidad.


El esquema empleado para la representación de imágenes digitales es RGB donde se emplea un vector para representar la composición de colores, de manera que cada pixel tenga asociadas las combinaciones correspondientes tres colores primarios (RGB), utilizando para cada color una representación de 8 bits.Por lo tanto, una imagen a color emplea 24 bits por cada pixel, necesitándose un total de (2^8)^3 = 16,777,216 valores posibles de color.
De esta forma, para una imagen con N x M elementos, existe un vector que contiene la intensidad asociada a cada color primario, que se corresponde con las coordenadas (x,y) de la siguiente forma:

|
|
.. figure:: formulaVectorColor.png

	Vector de color para una coordenada en la imagen
|


Por lo tanto, la representación de una imagen de colores se reduce a realizar combinaciones entre el vector RGB de cada pixel: 

|
|
.. figure:: imagenColor.png
	:scale: 60%

	Representación de una imagen digital a color
|
|

.. figure:: imagenColorvsGreyScale.png

	Representaciones de imagen en escala de grises vs imagen de color
|

Existen varias aproximaciones para afrontar el procesamiento de imágenes de color, aunque se pueden clasificar en 2 grupos generales: Aquellas aproximaciones que procesan cada componente de la imagen individualmente, para luego formar la imagen de salida con éstos; Y aquellas aproximaciones que trabajan con los colores de los pixeles en la imagen directamente. Este tipo de imágenes pueden ser procesadas con algunos los tipos de técnicas que se emplean con las imágenes de escala de grises, mientras que algunas tienen que ser modificadas para ser aplicadas sobre las bandas de color individuales.


Imágenes indexadas	
~~~~~~~~~~~~~~~~~~

En general las imágenes indexadas solo emplean un subconjunto pequeño de los 16 millones de colores, por lo que para mejorar la eficiencia de almacenamiento, la imagen puede tener asociado un mapa de color o paleta de colores, la cual es solamente un listado de todos los colores en la imagen. Así, cada pixel tiene un valor que no da su color, como en la imagen RGB, sino que es un índice al color en el mapa.
Este tipo de imágenes digitales, se emplea en algunos formatos donde la cantidad de colores permitidos para una imagen es de 56 colores o menos, como en el formato GIF.
|

.. figure:: imagenIndexada.png
	:scale: 50%

	Imagen de color indexada
|


Procesamiento de imágenes
+++++++++++++++++++++++++

Debido a que el procesamiento de imágenes abarca varios tipos de imágenes, comprendidas a lo largo de todo el espectro electromagnético, éste tiende a solaparse con otras áreas como el análisis de imágenes,basado en la extracción de información de utilidad desde la imagen, y la visión artificial, que es un área de la inteligencia artificial cuyo objetivo es lograr que una computadora adquiera conocimiento y pueda efectuar decisiones, basada en imágenes o video de entrada.
Así,el procesamiento de imágenes digitales, es un conjunto de técnicas que toman una imagen como entrada y, por medio de una computadora, producen una imagen de salida y adicionalmente posibilitan, extraer información y reconocer objetos en ésta.

Dependiendo del nivel de abstracción que manejan los procedimientos del procesamiento de imágenes, se pueden clasificar éstos en distintos tipos:

* Procesos de bajo nivel, que aceptan imagen como entrada, y ejecuta operaciones primitivas sobre ésta como la reducción de ruido, mejora del contraste y aplicación de filtros sobre la imagen para mejorar alguna característica (como aumentar el brillo entre áreas oscuras y con brillo), y producen una imagen modificada como salida.
* Procesos de nivel medio, que abarcan tareas como la segmentación (división de la imagen en partes), descripción de dichos objetos para reducirlos a una forma aceptable para el procesamiento por computadora, y el reconocimiento de objetos individuales(o clasificación de objetos). Estos procesos se caracterizan por el hecho de que las entradas son generalmente imágenes, pero sus atributos son atributos extraídos de una imagen, tales como: bordes, contornos, objetos individuales,etc.
* Procesos de alto nivel, que involucran  generar conocimiento a partir de éstos objetos ensamblados, y efectuar operaciones relacionadas con el  análisis de imágenes y algunas operaciones relacionadas con el campo de visión por computadora.
 
Existen distintos tipos de operaciones que pueden aplicarse sobre una imagen según el objetivo que se persiga, aunque los tipos más frecuentes son las siguientes:

.. pagina 49 gonzales, image processing.

* Aplicación de filtros y mejora la imagen. Estas técnicas buscan manipular la imagen, de manera que el resultado sea mas adaptable que la original para una aplicación específica. Esto se hace   con el fin de recuperar detalles que no se visualizan debido al bajo nivel de brillo, o simplemente subrayar ciertas características de interés en una imagen. Un ejemplo de este tipo de operaciones es cuando se aumenta el contraste para mejorar visualmente los objetos que se perciben en la imagen.

* Restauración y reconstrucción de la imagen. Este tipo busca mejorar la apariencia la imagen, sin embargo a diferencia de la mejora de imagen, esta técnica es objetiva debido a que se basan en modelos probabilísticos de degradación de imagen, mientras que la primera se basa en la subjetividad del observador para establecer una mejora adecuada. La restauración intenta recuperar una imágen que ha sido degradada empleando un conocimiento previo del fenómeno de degradación, por lo que estos procesos se encuentran orientados hacia el modelado de la degradación y la aplicación del proceso inverso, para recuperar la imágen original.


* Procesamiento de color de imagen. Debido a que el color se considera como un descriptor potente para el reconocimiento y extracción de objetos de una escena, se han desarrollado métodos que permiten emplearlo en el procesamiento de imágenes. El procesamiento de color se divide en dos grandes áreas: el procesamiento de color completo (full-color processing) y el procesamiento de pseucolores(pseudocolor processing). En la primer categoría, las imágenes son adquiridas  con un sensor que soporta el color, mientras que en la segunda categoría se enfoca en asignar un color a una intensidad o rango de intensidades en escala de grises.
   
* Wavelets. Las Wavelets son un conjunto transformaciones que forman parte del área de procesamiento de señales e imágenes denominado teoría de multiresolución, que abarca un conjunto de técnicas, incluyendo la división de bandas de una señal (subbanding), filtrado de voz digital y representación piramidal de una imagen. Esta rama se relaciona con la representación de imágenes (o señales) en más de una resolución, con el fin de obtener a una resolución específica, características que no se podrían identificar en otra resolución. Este tipo de herramienta es utilizada ampliamente para la compresión y la representación piramidal de una imagen. Esta última fue originalmente aplicada para la visión artificial y la compresión de imágenes, y consiste en subdivide subdividir una imagen con el fin de obtener una colección de imágenes de menor resolución organizadas en forma de imagen para su posterior procesamiento.
  
.. figure:: piramideImagen.png

	Representación piramidal para un arreglo de imagen de 2-Dimensiones de N x N
|


* Compresión.El objetivo de la compresión (o coding) es representar una imagen digital con la cantidad mínima de bits sin pérdida de información, persiguiendo así, la aceleración de la velocidad de transmición y reducción del ancho de banda necesaria para transmitir las mismas y la minimización del espacio requerido para almacenarlas, manteniendo a la vez en la fidelidad de la misma. La compresión es posible porque existe una redundancia presente en las imágenes, que es proporcional a la cantidad de correlación entre las muestras de datos. Por ejemplo, en imágenes estáticas existe un alto grado de correlación en los alrededores de un pixel, mientras que en los videos ésta se encuentra presente entre frames sucesivos del mismo. De esta forma para lograr un grado eficiente de compresión, estos métodos intentan remover los datos redudantes como así también, aquellos que se perciben pero son irrelevantes, produciendo que las imágenes de entrada y salida sean visualmente iguales, y no necesariamente numéricamente iguales.Las técnicas de compresión de las imágenes,se emplean frecuentemente en la extensión de las mismas, que a la vez representan el estándar seguido para la compresión como JPEG (Joint Photographic Experts Group).
  
* Procesamiento morfológico. La morfología se relaciona con la forma y las relaciones entre las partes de una imagen. El procesamiento morfológico consiste en aquellas herramientas que permiten extraer componentes de la imagen que son útiles en la representación y descripción de la forma, esto es atributos tales como componentes conectados, límites, skeletons (conjunto de elementos de una imagen que representan la forma de la misma se encuentran equidistantes a los límites) y el convex hull (el conjunto mínimo de puntos o elementos de la imagen, que unidos por líneas rectas, representan la misma). 
Además, el procesamiento morfológico abarca las técnicas pre-procesamiento y post-procesamiento complementarias que se emplean junto a los procedimientos descritas anteriormente, tales como filtrado o filtering, thinning, region filling(rellenado con información de los elementos que componen una región) y pruning(método empleado para la eliminación de elementos de imagen excedentes producto del empleo de skeletons y thinning).
  

* Segmentación.La segmentación de una imagen es el proceso de subdividir los pixeles en una imagen en regiones uniformes y homogéneas, donde cada región  es un grupo de pixeles, que representa un objeto o una parte de la escena que se muestra en la imagen. Así, la segmentación permite obtener agrupaciones de pixeles que comparten características similares, interconectadas y no solapadas, donde cada pixel de una región o segmento en la imagen adquiere una etiqueta de región que indica la región a la que pertenece.
Este proceso es uno de los más importantes elementos en análisis de imágenes automatizado, principalmente porque posibilita extraer aquellas entidades de interés en la imagen para aplicar otros métodos de procesamiento, como la descripción y el reconocimiento.


* Representación y descripción. Este proceso mayormente se emplea a continuación del proceso de segmentación, ya que ésta produce datos relacionados con los pixeles contenidos en el límite o en la región y es preferible emplear esquemas que compacten la información segmentada para mejorar el procesamiento de descriptores.
Estas técnicas, consisten en transformar los pixeles que forman una región en una representación conveniente para su procesamiento. La representación de una región proporciona dos alternativas: Representar la región en términos de sus características externas (su límite o boundary), describiéndose el limite por sus características como su longitud, la orientación de la línea recta que conecta sus puntos extremos, y el número de concavidades en el límite; O representarla según sus características internas, es decir, los pixeles que comprenden la región. 
En este caso, se emplean características propias de la región tales como el color y la textura. La característica principal de la textura, es que consiste en la repetición de un patrón o conjunto de patrones sobre una región. Éste puede ser repetido exactamente o con pequeñas variaciones de posición y, ciertas características como: forma, tamaño, color y orientación de los elementos que forman el patrón pueden variar sobre la región.Algunas veces, la diferencia entre texturas se obtiene por medio del grado de variación de los mismos o, en la distribución estadística de los elementos del patrón.
|

.. figure:: ejemplosTexturas.png

	Ejemplos de texturas artificiales (a-b) y texturas naturales(c-e)



Estudios relativos a la detección de fallas
"""""""""""""""""""""""""""""""""""""""""""

En lo que respecta al procesamiento de imágenes, una de las aproximaciones que se han empleado dentro de esta área es la de Korch y Brikalis :cite:`antecedentesProcImg1`, donde el reconocimiento de los tipos de falla consiste caracterizar los distintos tipos de falla  por medio de sus propiedades visuales (como las sombras alrededor de la misma, la forma aproximada, la apariencia visual de la textura dentro de la falla) y emplearlas en conjunto con un modelo que cuenta con tres fases de procesamiento: Segmentación de la imagen, extracción de forma y comparación de texturas.




Proyectos basados en sensores de vibración
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

AGREGAR INFO DE 2 O 3 PAPERS


Proyectos basados en el uso de reconstrucción 3D
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


AGREGAR INFO DE 2 O 3 PAPERS




Aplicaciones web y móviles existentes para la notificación de fallas
--------------------------------------------------------------------

ACA INCLUIR LOS SISTEMAS WEB EN "Ejemplos de otros sistemas para el registro de fallas.txt"


