Antecedentes de software para la gestión de fallas viales
=========================================================

Pavimento
---------

El pavimento de una calle o autopista, es una estructura compuesta de un conjunto de capas de materiales procesados sobre el suelo, cuya función consiste en distribuir las cargas de los vehículos al sub-suelo y permitir el tránsito de los mismos. La estructura del pavimento debería proveer una superficie de calidad aceptable para la circulación de vehículos, resistencia adecuada al resbalamiento,reducir la contaminación de ruido producto de la circulación de los vehículos, una superficie impermeable, de manera que el suelo que esta debajo de las capas de material este bien protegido, resistencia estructural (con el fin de soportar todo tipo de fuerza aplicada sobre él) y un diseño con un ciclo de vida prolongado y bajo costo de mantenimiento.

Los pavimentos se pueden clasificar en dos tipos diferentes:

* Pavimento de rígido: Es una estructura compuesta por losas de hormigón cuya resistencia a la flexión es relativamente elevada.
Los pavimentos rígidos se integran por una losa de concreto de cemento portland, que se encuentra situada por encima de una capa base de grava, y ésta a la vez descansa en una capa de suelo compactado, denominada subrasante.


.. figure:: pav-rigido.png
   :scale:	80 %

	Estructura del pavimento rígido


* Pavimento flexible: Es una estructura compuesta por capas donde uno de los materiales presentes es el asfalto, lo que permite la deflexión (la deformación que del material como producto de una fuerza externa) bajo las cargas.
Los pavimentos flexibles se componen de una capa de mezcla asfáltica u hormigón asfáltico, que consiste en un agregado de asfalto y materiales minerales (como áridos) compactados y extendidos. ;Ésta se expone a las condiciones más severas debido al clima y tráfico, una capa base que se compone de materiales áridos (conjunto de materiales obtenidos de la fragmentación de rocas y arenas, tales como la grava, la gravilla y la arena), una capa de sub-base con materiales de calidad inferior a los empleados en la capa base.

.. figure:: pav-flexible.png
   :scale:	80 %

	Estructura de pavimento flexible



Tipos de juntas
---------------

Los senderos viales, tales como calles, autopistas, se encuentran sometidos a diversos cambios de temperatura durante el día, a diferencias de temperatura considerables entre las distintas estaciones del año, a cambios de humedad constante, y durante su construcción, a los tiempos de parada debido a las jornadas de trabajo con horas fijas, provocan que el material sufra dilataciones y contracciones y, si este material se encuentra extendido en una porción considerable de terreno, se producirá el agrietamiento aleatorio e irregular del mismo, a corto plazo. Para evitar ésto, se emplean juntas en el pavimento,como mecanismo de control de fisuras, que consisten en cortes realizada con maquinaria especial a lo largo y ancho del material, a una profundidad establecida según las propiedades de éste y de la calle, que lo divide en losas. Estas divisiones, se realizan a una distancia aproximada a la que aparecerían las fisuras, ya que en caso contrario, se fisurarían aquellas losas con dimensiones excesivas.

En base a la posición de las juntas respecto del avance del hormigonado, las juntas en el pavimento se pueden clasificar en juntas longitudinales, que son aquellas paralelas a dicho avance, o juntas transversales, que son aquellas perpendiculares según el avance del mismo. Por otro lado, las juntas se pueden clasificar respecto del tipo de función que cumplen como:

* Juntas de contracción: Pueden ser juntas tanto transversales como longitudinales, y su fin es limitar el tamaño de las losas, disminuyendo hasta valores aceptables, el nivel de tensión producida por fenómenos de retracción como por la variación de temperatura por distancia(gradiente térmico), de manera de evitar roturas en el material.
   
* Juntas de construcción: Son las juntas que se producen entre bandas del pavimento, o también en una misma banda, entre losas que se encuentran de manera contigua que se construyen con un tiempo de parada prolongado.

* Juntas de dilatación: Son las juntas que se realizan con el fin de absorber las expansiones del material como consecuencia de los aumentos de temperatura, evitando empujes sobre éste que podrían producir la rotura del mismo. En este tipo de junta,se emplea un material compresible (madera, poliestireno expandido, laminas de poliuretano,etc.) entre las losas con contacto, o entre la losa y otros elementos, como muros y arquetas. 
  
  
Tipos de fallas sobre pavimentos rígidos y flexibles
----------------------------------------------------

Fallas sobre pavimentos rígidos
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Dentro de los tipos de fallas que pueden ocurrir en pavimentos rígidos se encuentran los siguientes:

* Deficiencia de sellado: Este tipo de falla se ocasiona cuando se deterioran el sello de las juntas, por ejemplo, cuando existe fluencia fuera de la caja, despegado de ambas paredes, incrustación de materiales ajenos. El método de reparación de este tipo de falla consiste en realizar un sellado de juntas y de las grietas.

.. figure:: pav-rigido-deficiencia-sellado.png
   :scale: 70 %

   Deficiencia de sellado

* Losas desniveladas:  Ocurre cuando se desintegran las aristas de una junta, ya sea de manera longitudinal o transversal, con pérdida de trozos. Para este tipo de falla el método de reparación consiste en un sellado de juntas y grietas, o reparación de espesor parcial, que consiste en reponer las saltaduras de material superficial en juntas y grietas.

.. figure:: pav-rigido-losas-desniveladas.png
   :scale: 30 %

   Losas desniveladas

* Grietas: Una grieta se define como una abertura larga y estrecha en una losa de material, y ésta dependiendo de su ubicación en la losa, puede ser una grieta de esquina, longitudinal (si se extiende a lo largo de una losa) o transversal (si se extiende de manera perpendicular al volcado del material de la losa). El método de reparación para este tipo de falla, consiste en el sellado de juntas y grietas, y la reparación en todo el espesor. 
  
.. figure:: pav-rigido-grieta-longitudinal.png
   :scale: 50 %

   Grieta longitudinal


* Desintegración: Esta falla se produce cuando ocurre un desgaste progresivo de la superficie, dejando al material árido expuesto. El método de reparación de este tipo de falla, consiste en realizar una reparación de espesor parcial, en la que se corta la porción de la zona a reparar con una profundidad de corte preestablecida, se limpia la zona y se rellena la zona con un material especial de sellado de juntas.

.. figure:: pav-rigido-desintegracion.png
   :scale: 50 %

   Desintegración




* Baches: Un bache se define como una cabidad, generalmente de forma redondeada producto de la pérdida o hundimiento del pavimento en una parte de la superficie. El método de reparación para este tipo de falla depende del deterioro del mismo, y es especial para cada caso.
  
.. figure:: pav-rigido-bache.png
   :scale: 40 %

   Bache


* Levantamiento: Es el levantamiento de una porción de la losa, localizado en ambos lados de una junta transversal o grieta.El método de reparación consiste en realizar una reparación en todo el espesor, en la que se remueve y reemplaza una porción de la losa en todo su espesor, con el fin de reparar aquellas partes de la losa con un alto grado de daño.
|
   
.. figure:: pav-rigido-levantamiento.png
   :scale: 50 %

   Levantamiento de juntas

* Escalonamiento de juntas o grietas: Este tipo de falla ocurre cuando existe un desnivel entre dos superficies del pavimento, separadas por una junta transversal o grieta. El método de reparación para este tipo de falla es el fresado de la superficie, donde se separan las partes defectuosas del pavimento, de las que se encuentran en buen estado.
  
.. figure:: pav-rigido-escalonamiento-juntas.png
   :scale: 70 %

   Escalonamiento de juntas


* Descenso de banquinas: Es la diferencia de alturas que existe entre el borde del pavimento y la banquina. El método de reparación de este tipo de falla, consiste en realizar el nivelamiento de las banquinas no revestidas.

.. figure:: pav-rigido-descenso-banquinas.png
   :scale: 40 %

   Descenso de banquinas

.. raw:: latex
	
	\newpage

* Separación banquina-pavimento: Consiste en una rajadura entre el borde del pavimento y la banquina del sendero vial.El método de reparación consiste en realizar un sellado de juntas y grietas.

.. figure:: pav-rigido-separacion-banquina-pavimento.png
   :scale: 50 %

   Separación banquina-pavimento


* Parches deteriorados: Este tipo de falla surge cuando una porción de la superficie del asfalto ha sido removido y reemplazado por otro (como hormigón o asfalto), y ésta se ha dañado. El método de reparación de este tipo de falla, varía según el deterioro, y requiere una reparación especial.

.. figure:: pav-rigido-parche-deteriorado.png
   :scale: 40 %

   Parches deteriorados

Fallas sobre pavimentos flexibles
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

* Exudación: Este tipo de falla se presenta cuando el asfalto pierde sus agregados pétreos en la superficie. El tipo de reparación para esta falla consiste en enarenar y realizar una reparación superficial.

.. figure:: pav-flexible-exudacion.png
   :scale: 50 %

   Exudación


* Ahuellamiento y depresiones: El ahuellamiento es producido por el hundimiento de manera longitudinal del pavimento, y éste coincide con el área donde la mayor parte de los vehículos circula. Mientras que depresión, se considera un ahuellamiento de longitud menor al del ahuellamiento.
Si la profundidad máxima del ahuellamiento es inferior a los 20 mm, se realiza perfilado del pavimento, si la profundidad máxima es mayor a 20 mm pero inferior a 40 mm se realiza relleno de la rodadera, y si ésta es superior a 40 mm, se realiza una reparación local del pavimento.

.. raw:: latex
	
	\newpage

.. figure:: pav-flexible-ahuellamiento.png
   :scale: 50 %

   Ahuellamiento y depresión


* Grietas: Este tipo de falla tiene las mismas características que para pavimento rígido.

  
* Hundimiento del borde y ahuellamiento: Ocurre cuando se hunde el borde del material que limita con el margen.El método de reparación depende de la profundidad máxima del mismo, si ésta es menor a 20 mm se emplea perfilado del pavimento, si es superior a 20 mm pero inferior a 40 mm se emplea la técnica de relleno de rodadera, si es mayor a 40 mm se realiza una reparación local de la estructura del pavimento.

.. figure:: pav-flexible-ahuellamiento-borde.png
   :scale: 50 %

   Hundimiento del borde y ahuellamiento


* Baches: Este tipo de falla produce un hundimiento local del sendero vial, con agrietamiento  en malla cerrada y generalmente pérdida parcial de bloques de la capa de rodadura.Las técnicas de reparación de este tipo de falla consisten en restauración local de la estructura del pavimento, o bacheo sobre la base.
  
.. figure:: pav-flexible-baches.png
   :scale: 50 %

   Baches

.. raw:: latex
	
	\newpage

* Pérdida local de áridos: Este tipo de falla se presenta cuando ocurre una pérdida de una porción de la capa superficial. El método de reparación para este tipo de falla consiste en reemplazar el material afirmado.

.. figure:: pav-flexible-perdida-aridos.png
   :scale: 50 %

   Pérdida local de áridos


* Pulimiento o peladuras: Produce desprendimientos de la última capa de tratamientos superficiales. El método de reparación varía según la severidad, siendo un método de tratamiento superficial simple con una profundidad menor a 25 mm y área menor a 0,8 m2, y siendo nivelación con sobrecarpeta para profundidad o área mayores a 25 mm y 0,8 m2 respectivamente.

.. figure:: pav-flexible-pulimiento.png
   :scale: 50 %

   Pulimiento o peladuras


* Deformación: Se visualiza en pavimentos donde se produce una desviación longitudinal del material con respecto a su perfil original (asentamientos en el pavimento). El método de reparación con profundidad de la flecha de 13 a 25 mm o entre 25 mm y 50 mm es tratamiento superficial con medida preventiva, mientras que si se superan los 50 mm, se emplea bacheo seguido por aplicación de tratamiento superficial.
  
.. raw:: latex
	
	\newpage

.. figure:: pav-flexible-deformacion.png
   :scale: 50 %

   Deformación


Proyectos de software anteriores para la detección de fallas sobre el pavimento
-------------------------------------------------------------------------------

Debido a que la recolección manual de fallas es una tarea costosa con respecto al tiempo y al esfuerzo, durante años se  han publicado varios papers y tesis con el fin de automatizar esta tarea a través del uso de distintos dispositivos para el sensado, combinados con distintas técnicas de localización, registro de fallas y análisis de la información sensada. Los papers y tesis publicados hasta la fecha se pueden clasificar según el tipo de sensor que emplean, en tres grandes grupos:

* Detección de fallas utilizando técnicas basadas en procesamiento 2D con imágenes o video.
* Detección de fallas por medio de sensores de vibración(acelerómetros).
* Detección de fallas empleando modelos de reconstrucción 3D (stereovision o dispositivos equipados con laser lasers).


Proyectos basados en procesamiento de video e imagen
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Conceptos de procesamiento de imágenes
""""""""""""""""""""""""""""""""""""""

Digitalización de imágenes
++++++++++++++++++++++++++

El mundo percibido diariamente por las personas se manifiesta en una variedad de formas, colores y texturas que la visión humana puede adquirir, integrar e interpretar con relativa facilidad, como así también, reconocer éstas en sus representaciones asociadas en textos, presentaciones multimedia, imágenes o video digital. No obstante, existe una gran cantidad de radiación que puede ser sensada, que se encuentra delimitada por el espectro electromagnético, descubierto por Sir Isaac Newton en 1666, cuando un rayo de luz atravesó un a través de un prisma, y Newton observó que el haz de luz es blanco, sino que se compone de un espectro continuo de colores desde violeta en un extremo (0.43 micrometros) hasta rojo en el otro(0.79 micrometros). 


|
.. figure:: espectroElectromagnetico.png
   :scale:	80 %

	El espectro electromagnético dividido y ampliado.
|

Como se puede observar en la figura anterior, en un extremo del espectro se encuentran las ondas de radio que se caracterizan por poseer longitudes de onda millones de veces mas largas a las de la luz visible, mientras que en el otro extremo se encuentran los rayos gamma con longitudes de onda millones de veces más pequeñas. El espectro electromagnético se puede expresar en función de la energía, la frecuencia o la longitud de onda (wavelength, LAMBDA). La longitud de onda (LAMBDA) y la frecuencia se encuentran relacionadas por la expresión:
|
LAMBDA = c/v

donde c es la velocidad de la luz (2.988 x 10 ^8 m/s). Por otro lado, la energía de varios componentes del espectro electromagnético se define en la expresión:
|
E = h*v(eq1)

donde h es la constante de Planck. Las unidades de las longitudes de onda se miden en metros, empleándose las medidas micrometros y nanómetros frecuentemente. La frecuencia se mide en Hertz(Hz), con 1 Hertz siendo igual a un ciclo de onda sinusoidal por segundo. Una unidad de medida para la energía en el espectro electromagnético es el electron-volt.

Por lo tanto, las ondas electromagnéticas pueden ser vistas como ondas sinusoidales con longitud de onda LAMBDA, o pueden ser consideradas como un flujo de partículas sin masa, cada una viajando en un patrón con forma de onda y moviéndose a la velocidad de la luz. Cada partícula sin masa, contiene una cierta cantidad de energía denominada fotón(photon). De la ecuación eq1 , se puede observar que la energía es proporcional a la frecuencia, por lo que cuanto más alta sea la frecuencia el fenómeno electromagnético llevará mas energía por fotón. Así las ondas de radio tienen fotones con baja energía, las microondas tienen más energía que las ondas de radio, las infrarojas aún más, siendo la luz visible, luz ultravioleta,los rayos X y finalmente los rayos gamma los que tienen mayor cantidad de energía de todos. Esta es la razón por la cual los rayos gamma son los más dañinos para los organismos vivientes.

|

.. figure:: ondaSinusoidal.png
   :scale:	80 %

	Representación gráfica de la longitud de onda (LAMDA)


Sin embargo, el ojo humano sólo puede capturar la luz visible de la radiación electromagnética, que representa una porción mínima de la radiación que puede ser percibida, y aunque esta banda es óptima ya que el volumen de información se encuentra reducido, es altamente confiable y disponible (ya que se encuentra fuertemente proyectada por el Sol y la atmósfera de la tierra es lo suficientemente transparente como para percibirla), la radiación de otras bandas puede ser igualmente útil para ciertas ramas de la ciencia, que graban y hacen uso de casi todo el espectro y emplean esta información con el objetivo de obtener un mejor concepto de la realidad física. Un ejemplo de esto son las ondas de sonido de alta frecuencia o ultrasonido, que son usadas para crear imágenes del cuerpo humano mientras que las imágenes de baja frecuencia son empleadas por compañías, para crear imágenes de la superficie de la tierra. Aunque la captura de imágenes se basa principalmente en la energía generadas por las ondas electromagnéticas, existen otros métodos para la generación de imágenes, tales como capturar el sonido reflejado desde un objeto con el fin de obtener imágenes ultrasónicas, o rayos de electrones como los que emplean los microscopios de electrones para obtener imágenes que permitan recolectar información respecto de especímenes biológicos e inorgánicos, incluyendo microorganismos, muestras de biopsias, metales y cristales. 

Las imágenes,aunque tengan distintas fuentes, comparten el hecho de que existe una radiación que es emitida desde alguna fuente para posteriormente interactuar con algún tipo de material, luego es sensada y trasladada en una señal eléctrica que puede ser digitalizada. Las imágenes se pueden clasificar según la forma en la que la interacción con el dispositivo de sensado ocurre en 3 categorías generales:

* Las imágenes de reflexión son aquellas en que la radiación ha sido reflejada desde la superficie de un objeto. Ésta puede ser del ambiente o artificial, y puede provenir desde una fuente localizada o desde fuentes múltiples. Este tipo de imágenes son las que se perciben día a día por las personas por medio de la vista, mientras que algunos ejemplos de imágenes no visibles de este tipo incluyen imágenes por radar, imágenes por sonar y algunos tipos de imágenes por microscopio. El tipo de información que puede ser extraída desde este tipo de imagen es generalmente respecto de la superficie de los objetos, su forma, color, textura y reflectividad.
* Las imágenes de emisión son aquellas cuya radiación es emitida por el objeto que se desea capturar, como las imágenes térmicas o infrarojas, y que son usadas por áreas como la medicina, pruebas militares, o en objetos luminosos como bombillas de luz, estrellas, imágenes de resonancia magnética (MRI), las cuales obtienen información en base a la capacidad de emisión de las partículas. Cuando se emplea este tipo de imágenes se desea obtener información respecto de la estructura interna del objeto, aunque también pueden ser empleadas para información externa, por ejemplo, una cámara térmica utilizada en situaciones con baja iluminación, con el fin de producir una imagen que capture los objetos que producen calor en una escena.
* Las imágenes de absorción donde la radiación atraviesa el material que compone el objeto y es absorbida o atenuada por éste parcialmente, lo que proporciona información relacionada con la estructura interna del mismo. El grado de absorción determina el nivel de la imagen registrada. Ejemplos de este tipo de imágenes son los rayos X, imágenes de transmisión microscópicas y ciertos tipos de imágenes sónicas.   
|

.. figure:: tiposInteraccionImagenes.png
   :scale:	80 %

	Tipos de interacción para el sensado de imágenes


Para que un sensor pueda captar un objeto de determinado tamaño, es necesario que la longitud de onda del sensor sea igual o menor al tamaño de del objeto, por lo que este requerimiento junto con el material del sensor, establecen los límites de la capacidad de captura del sensor de imagen y su clasificación en distintos tipos, tales como sensores infrarojos, de luz visible,etc. Así, con el fin de capturar imágenes digitales en las distintas bandas del espectro electromagnético, es necesario emplear sensores que puedan captar la energía irradiada en cierto rango y produzcan una señal eléctrica de salida (generada por una combinación entre el material sensible a la radiación del sensor y la fuente de alimentación del mismo), que permita la representación de una imagen del mundo tridimensional de interés en formato digital.


.. figure:: sensorCaptura.png
   :scale: 90%
   
	Sensor individual de captura


Cuando un fenómeno es captado por un dispositivo con uno o varios sensores, estos en general producen una onda de voltaje continua cuya amplitud y forma esta relacionada a la radiación emitida o reflejada desde el objeto, por lo que para crear una imagen digital, es necesario realizar una conversión estos datos en un formato digital, dando como resultado una imagen digital. Este proceso comienza con la conversión de las coordenadas espaciales de la imagen a una matriz multidimensional que pueda ser indexada por valores numéricos(también llamado proceso de muestreo o sampling), de esta forma la señal puede ser almacenada y procesada como un arreglo de M filas x N columnas de valores discretos, donde cada uno de los elementos (i,j) que pueden ser indexados en la matriz se denomina elemento de imagen(picture element), pel o pixel. Así si una imagen digital contiene M x N pixeles, se representa por una matriz de M x N elementos conteniendo desde 0 hasta M-1 índices en las filas y desde 0 hasta N-1 índices en las columnas.
Cuando la cantidad de pixeles muestreados no es suficiente(undersampling) como para representar la imagen, se produce un efecto denominado aliasing, que produce que la imagen visual pierda el patrón de la imagen original que intenta representar, produciendo una falso patrón y una imagen distorcionada. Como se observa en la siguiente imagen de una huella digital, a medida que la densidad de pixeles muestreados disminuye, la calidad de la imagen empeora y se produce éste efecto:


.. figure:: aliasing.png
   :scale: 80%
   
	Efecto de aliasing. 256x256 (2^8*2^8=65,536 muestras). 128x128(2^7*2^7=16,384 muestras).64x64(2^6*2^6=4,096 muestras)
|


.. figure:: imagenPixels.png

	Representación de un array de imagen de 10 x 10

.. NOTA: VER SI AGREGAR ACA LAS PROPIEDADES DE LOS PIXELES. PAG 83.Pretince Hall Gonzales 2 ed.


El siguiente paso consiste en realizar la cuantificación o quantization, donde se realiza la conversión de las intensidades analógicas captadas por los sensores a valores numéricos discretos, asignando un valor a cada pixel muestreado, de manera que la imagen reconstruida de los valores muestreados sean de una calidad lo más aproximada a la real y el error introducido por la cuantificación sea mínimo.
Con el fin de cuantificar, el rango de valores dinámicos que puede adoptar los pixeles de una imagen se dividide en un rango finito de intervalos, y a cada intervalo se le asigna un valor.Cuanto mayores sean los intervalos disponibles para cuantificación, la imagen digitalizada se aproximará con más fidelidad a la imagen real. 
La cuantificación se puede realizar de manera uniforme, cuando los valores de intensidad tienen mayor probabilidad de caer en intervalos regulares y se opta por dividir el rango de niveles en intervalos igualmente espaciados. Por otro lado, cuando la imagen adopta valores en un rango con una frecuencia prolongada y otros valores de manera infrecuente, es preferible emplear la cuantificación no uniforme. 




.. figure:: cuantificacionUniformeNoUniforme.png
   :scale: 70%

	Cuantificación de imagen de 2 dimensiones.Cuantificación uniforme (a).Cuantificación no uniforme (b).


De esta forma, el proceso de digitalización requiere los valores de M,N y la cantidad de niveles de intensidad L( niveles de gris en el caso de las imágenes con escala de grises o de valores en las bandas roja,verde y azul para las imágenes a color) como valores positivos, permitidos para cada pixel. No obstante, debido a las consideraciones de hardware, procesamiento y almacenamiento, el número de niveles es típicamente una potencia de 2:


.. math:: L = 2^k
	:label: formulaNivelIntensidad
.. .. math:: e^{i\pi} + 1 = 0
   :label: euler
.. Euler's identity, equation :eq:`euler`, was elected one of the most
.. beautiful mathematical formulas.


Donde k es el número de bits empleados para representar el nivel de cada pixel. En general, el número de bits k se encuentra entre 1<=k<=8, empleándose k=1 para imágenes binarias, k=8 para imágenes por escala de grises (donde cada nivel ocupa cun byte) y, para el caso de las imágenes a color, con múltiples valores, cada nivel de color ocupa 8 bits usando los colores rojo,verde y azul (RGB), empleándose 24 bits por pixel con el fin de representar el color de éste. 
Así, cuando una imagen puede tener 2^k niveles de gris, es una práctica común referirse a la imagen como una "imagen de k-bits".Por ejemplo, una imagen con 256 niveles posibles es llamada una imagen de 8 bits.Por lo tanto, la cantidad de bits requeridos para almacenar una imagen será:

.. math:: b = M x N x k
	:label: cantBitsNecesarios

.. figure:: resultadoDelProcesoCuantificacion.png

   Representación del proceso de muestreo y cuantificación.Imagen continua captada por un dispositivo de sensado(a).Imagen muestreada y cuantificada(b).




Relaciones entre pixeles
++++++++++++++++++++++++
.. CONTENIDOS A INCLUIR: 
..	-Relaciones entre pixeles y DISTANCIA ENTRE LOS MISMOS, background,foreground, region,interpolacion,neirbourhood o ventana o mascara(masking).

Los pixeles Pk en la coordenada (i,j), con k siendo la cantidad total de pixeles con los indices i=1,2,...,n y j=1,2,...,m, que componen una imagen digital cuentan con distintas propiedades entre las que se encuentran las siguientes:

* Pixeles conectados: Un pixel en un punto P0 en (i0,j0) se conecta a otro pixel Pn en (in,jn) si y sólo si existe un camino desde P0 hasta Pn, que es una secuencia de puntos (i0,j0),(i1,j1)...(in,jn) tal que el pixel (ik,jk) es un vecino del pixel en (ik+1,jk+1) y Pk= Pk+1 para todos los k, 0 < k < n-1. La secuencia de pixeles distintos de un pixel a otro también se denomina camino digital (digital path) y, si el primer pixel del camino se encuentra conectado con el primer pixel, se denomina un camino cerrado.
  
* 4-vecinos(4-connected pixel): Cuando un pixel P en la ubicación (i,j) tiene cuatro vecinos en las coordenadas (i+1,j), (i-1,j), (i,j+1) e (i,j-1) se conocen como 4-vecinos.Es decir, que cada pixel esta a una unidad de distancia' de (i,j) y algunas de las ubicaciones de P yacen fuera de la imagen digital en el borde la imagen.


* 8-vecinos(8-connected pixel): Se dice que un pixel P ubicado en (i,j) tiene una conexión diagonal de 4 pixeles, cuando tiene pixeles en las coordenadas (i+1,j+1),(i+1,j-1),(i-1,j+1) e (i-1,j-1). Si además este pixel tiene 4-vecinos, se dice que estos pixeles son 8-vecinos de P. 


Otra propiedad de los pixeles es la adyacencia que se define en términos de los niveles de intensidad, siendo V el conjunto de valores de intensidad que un pixel puede adoptar, con V = {1} en imágenes binarias (considerandose adayacentes dos pixeles que tienen intensidad 1) y V siendo un subconjunto de todos los niveles de la imagen (para el caso de imagenes por escala de grises) y considerándose adyacentes dos pixeles cuyos valores de intensidad están en ese subconjunto. Existen 3 tipos de adyacencia:

* 4-adyacentes(4-adjacency). Dos pixeles P y Q con valores del conjunto V son 4-adyacentes si Q esta en el conjunto de los 4-vecinos de P.

* 8-adyacentes(8-adjacency).Dos pixeles P y Q con valores del conjunto V son 8-adyacentes si Q esta en el conjunto de los 8-vecinos de P.

* adyacencia mixta(m-adjacency o mixed-adjacency). Dos pixeles P0 y P1 con valores del conjunto V son m-adyacentes si: 

	* P0 es un 4-vecino de P1, o
	* Si P0 esta en una conexión diagonal de P1 y el conjunto de 4-vecinos de P0 y de P1 no tienen valores en común con el conjunto V de niveles.
 
* Componente conectado: Si dado un subconjunto de pixeles S en una imagen, dos pixeles P0 y P1 se dicen conectados si existe un camino digital que se compone de los pixeles en S.Así, para cualquier pixel P que este en S, el conjunto de pixeles que están conectados a él es llamado un componente conectado de S. Un conjunto de pixeles conectados (4 u 8 pixeles) forman un componente conectado,que representa un objeto en escena.

* Región. Dado un subconjunto de pixeles R en una imagen, R se denomina una región si es un componente conectado, y dos regiones R1 y R2 se dicen adyacentes si su unión forma un conjunto conectado, o disjuntas en caso contrario.


* Fondo(background) y Frente(foreground). Si una imagen contiene Rk regiones con k=1,2,...,N, la unión de todas las regiones se considera el frente, mientras que el resto de los pixeles que no esta en ninguna región se considera el complemento.

* Borde o Contorno(boundary,border,contour). El contorno de una región R es el conjunto de los puntos que son adyacentes a los puntos que no estan R(complemento), es decir, que éste se compone de aquellos pixeles en la región que tienen al menos un vecino que forma parte del fondo.Si R es una imagen entera(matriz de pixeles), entonces su contorno se define como el conjunto de pixeles en la primera y ultima fila y columna de la imagen, ya que una imagen no contiene más vecinos más alla de los bordes.

|

.. figure:: tiposConexionesImgBinaria.png
  
    Tipos de conexiones entre pixeles. 4-vecinos(a). 8-vecinos(b). Componente conectado y fondo(c).

Una vez que un objeto es identificado algunos de sus atributos se pueden definir de la siguiente manera:

* Área del objeto: El área de un objeto se da como la sumatoria de todos los pixeles i,j que forman el objeto(pixeles con valor 1).
* Ubicación del objeto: La ubicación del objeto se define como el centro del objeto en X e Y, calculados por medio de la sumatoria de las coordenadas del objeto dividido por el área del mismo. En la siguiente ecuación se puede observar la forma de calcular los centroides Xc e Yc:
|
|

.. figure:: calculoCentroide.png
   :scale: 80%
   
   Fórmula para el cálculo del objeto

* Orientación de un objeto: Cuando el objeto tiene una forma alargada, los ejes de la elongación producen la orientación del mismo.El eje de elongación es una línea recta tal que la suma de las distancias al cuadrado, de todos los puntos del objeto desde esta línea es mínimo(distancia perpendicular de un punto del objeto hacia la línea).
* Perímetro de un objeto: El perímetro de un objeto se obtiene sumando los pixeles que forman parte del límite del objeto y que son parte del área. El límite o contorno de un objeto esta formado por aquellos pixeles que tienen uno o más vecinos que no están en el área.

.. Nombres de conexiones en español --> http://scfi.uaemex.mx/hamontes/files/TI04%20-%20Relaciones%20basicas%20entre%20pixeles.pdf



Herramientas y técnicas sobre imágenes digitales
++++++++++++++++++++++++++++++++++++++++++++++++

.. COMANDO PARA CAMBIAR DIRECTORIO SCREENPRINT --> 
.. gsettings set org.gnome.gnome-screenshot auto-save-directory "file:///home/rodrigo/TESINA-2016-KINECT/DOCUMENTO_TESINA_FORMAL/tesinaInforme/"


..	-Tipos de operaciones que se realizan sobre una imagen (SUMA,RESTA,DIVISION,MULTIPLICACION y sus efectos a nivel de imagen, a nivel de pixel transformaciones espaciales),

.. -Dominio espacial:
..					- Operaciones de transformacion con pixeles, vecindarios(windows, o mask) e imagenes. Cap 3. Relacionado con 2 tipos de categorias de transformaciones: filtrado espacial(filtros de suavizado y sharpening) y transformaciones de intensidad.
.. 
.. -Dominio de transformaciones:
..					-Son metodos que se basan en transformar una imagen a un dominio de interes, procesarla en ese dominio y luego regresarla de vuelta al dominio inicial(imagen de salida). 
..					-Formula de Fourier y dominio de frecuencia, que son paralelos a las tecnicas descritas con el dominio espacial pero empleando las frecuencias de la imagen.
.. NOTA: Nivel h6 de identación.
.. NOTA:  FILTROS, E HISTOGRAMA DE FRECUENCIAS!!! 


De forma general, existen dos tipos de aproximaciones que pueden emplearse en una imagen para aplicar técnicas de mejora de imagen y transformación: Emplear técnicas que actúen dominio espacial de la imagen, es decir modificando ciertas características sobre los pixeles de la imagen directamente; O Emplear técnicas que se ejecutan sobre el dominio de frecuencias de la imagen, que consisten en realizar una conversión de los valores de la imagen para llevarla a otro dominio, ejecutar transformaciones sobre ese dominio y finalmente, realizar la transformación inversa para obtener la imagen de salida.      

Técnicas que sobre el dominio espacial
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Debido a que las imágenes se representan como matrices, es posible tanto aplicar operaciones aritméticas y lógicas entre matrices, como ejecutar operaciones que modifiquen características de los pixeles, con el fin de modificar ciertas características de éstas. Los tipos principales de operaciones que se pueden emplear se pueden clasificar en 3 tipos generales:

.. NOTA: VER pag. 55. Introduction to digital image processing with MATLAB. Filtrado espacial en realidad es una funcion de manipulacion de intensidad, pero produce un valor de intensidad tomando el valor de varios pixeles(neirbourhood pixel operation)???

* Operaciones de manipulación de intensidad (modificación del nivel de intesidad de uno o varios pixeles).
* Operaciones aritméticas entre matrices de la misma dimensión (estas operaciones incluyen suma,resta, multiplicación y división entre matrices).
* Operaciones geométricas de transformación (interpolación,traslación,rotación, filtrado espacial).


Operaciones de manipulación de intensidad
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

En este tipo de técnicas las operaciones las relaciones entre pixeles vecinos no se consideran, como así tampoco la localización de los pixeles, sino que se modifican las intensidades de los pixeles. Estas operaciones pueden realizarse sobre pixeles individuales, tomando como entrada el valor de intensidad de un pixel y produciendo el valor de intensidad transformado para ese pixel; O sobre un vecindario de pixeles(neighborhood), donde dada la coordenada de un pixel en la imagen de entrada f(x,y), se toman los valores de intensidad de un conjunto de pixeles vecinos y, por medio del procesamiento de estos valores, se obtiene el valor de intensidad para ese pixel en la imagen de salida g(x,y).

|
.. figure:: operacionesNeighborhood.png
	:scale: 70%

	Vecindario de pixeles


En la parte restante de la sección, se describen algunas de las herramientas que se emplean para modificar los valores de intensidad de una imagen asociadas al histograma de imagen (operaciones por pixeles individuales) y la operación de filtrado espacial (operación que abarca un conjunto de pixeles) y sus principales utilidades.


Histograma de imagen
####################
.. NOTA: Identacion h8

La herramienta básica para este tipo de operaciones es el histograma de imagen,que es una representación gráfica que agrupa las frecuencias de ocurrencias de cada nivel de intensidad (nivel de gris en imagenes por escala de grises) en los pixeles de la imagen. De esta manera, si se cuenta con K niveles de intensidad {0,1,...,K-1} y una cantidad NxM de pixeles, el histograma se define matemáticamente de la siguiente manera:

.. math:: Hf(k) = J
   :label: formulaHistogramaImagen


.. PAGINA 142 Image processing 3rd edition. Gonzales.

Donde f() es la función que mapea el nivel de intensidad a cada pixel P(x,y), y J representa la cantidad de ocurrencias de ese nivel en los pixeles, con K niveles.Aunque este tipo de histograma no contiene información espacial con respecto a la imagen, es una herramienta valiosa que permite visualizar si la distribución de niveles de intensidad en una imagen es correcta, o si la imagen tiene tonalidades mas oscuras o más claras. Por ejemplo, en un histograma que corresponde a una imagen con escala de grises los niveles más oscuros se concentran sobre la parte más baja de la escala del histograma, mientras que los niveles más brillantes están en la parte alta del diagrama. Así, una imagen por escala de grises con bajo contraste, tendrá un histograma cuyos puntos se encuentran centrados en la escala y abarcan pocos valores en el rango, mientras que si ésta tiene un contraste alto, los valores del histograma abarcarán un rango amplio de la escala y, su distribución tenderá a ser uniforme.



.. figure:: variosNivelesContraste.png
   :scale: 60%

   Imágenes con distintos niveles de contraste y sus histogramas asociados

En la siguiente figura se puede observar, que la figura de la izquierda presenta niveles de gris más oscuros, mientras que la figura de la derecha presenta niveles de grises con más brillo, lo que indica que han estado expuestas a condiciones de luz excesiva y escasa. 
|


.. figure:: histogramaImagen.png

   Histograma de imagen.
|

Algunas veces el histograma de imagen se normaliza, dividiendo la cantidad de ocurrencias en cada nivel de intensidad, por el número total de pixeles en la imagen(N*M), de manera que la sumatoria de los componentes de un histograma normalizado sea 1. 

El histograma de imagen es una herramienta básica empleada por varias técnicas de procesamiento de imágenes con intensidad como la mejora de imagen,además de proveer información de utilidad para la compresión y la segmentación de imágenes.  


Escalado de histograma
######################

El escalado de histograma consiste modificar el rango de niveles de intensidad que se consideran para representar un histograma.Este procedimiento dada una función f(n) que representa el histograma para cada uno de los n pixeles, consiste en multiplicar cada uno de estos valores por una constante numérica P (mayor o menor a 1):

.. math:: g(n) = P*f(n)
   :label: formulaEscaladoImagen

Por ejemplo si se emplea un histograma de una imagen de escala de grises, si el valor de la constante P > 1, los niveles de gris cubrirán un rango mas amplio que aquellos de la función del histograma f(), mientras que si P < 1 se empleará un rango de niveles de gris más reducido, lo que puede producir pérdida de información en la imagen y disminuir su nitidez.
| A continuación se pueden observar imágenes originales y los efectos de aplicar el histograma de imagen con dos escalas distintas:

.. _escaladohistograma:

.. figure:: efectoEscaladoHistograma.png
	:scale: 80%

	Efectos del escalado de histograma entre dos puntos A-B.

| 
.. figure:: estudiantesOriginal.png
	:scale: 70%

	Imagen de estudiantes original (izquierda) y su histograma de imagen asociado(derecha).

| 
.. figure:: estudiantesEscalaHistograma.png
	:scale: 70%

	Modificación de la escala del histograma con P=0,75, en este caso los niveles de gris de la imagen tienden a juntarse, provocando que la imagen disminuya su calidad.

| 
.. _librosoriginal:

.. figure:: imagenOriginalLibros.png
	:scale: 70%

	Imagen de libros(izquierda) y su histograma(derecha)

| 
.. figure:: librosEscalaHistograma.png

   Modificación de la escala del histograma con P=2. En este caso, la expansión de los valores del histograma de imagen, produce que se haga un mejor uso de los niveles de gris, produciendo una mejora en la nitidez de la misma



Negativo de imagen
##################

El negativo de una imagen consiste en escalar éstos con P=-1 revirtiendo el signo de los valores y  sumar un desplazamiento a los valores de intensidad de cada pixel K-1 con el fin de que estos se encuentren en el rango del histograma:

.. math:: g(n) = -f(n) + (K-1)
	:label: formulaImgInversa
|
|

.. figure:: imagenNegativa.png

   Imagen negativa con su histograma modificado
|

Esta técnica se emplea para mejorar imágenes donde se pierde el nivel de detalle en las regiones con niveles blanco y negro, percibiéndose ésta como demasiado oscura. Un ejemplo de esta operación es la inspección de imágenes telescópicas con campos de estrellas y galaxias, donde con una imagen negativa los objetos brillantes, aparecen con una tonalidad oscura sobre un fondo brillante que es mas sencillo de apreciar.   

Estiramiento de contraste(Contrast Stretching,Histogram Stretching)
###################################################################

Este procedimiento consiste en distribuir las frecuencias de los niveles de intensidad,por medio de una fórmula matemática, en un nuevo histograma donde éstos se encuentren distribuidos de manera uniforme y abarquen la escala completa de niveles de intensidad. Por ejemplo si se emplea un histograma de una imagen de escala de grises, como el de la figura :num:`Fig. #escaladohistograma`, donde los niveles de intensidad de toda la escala están en el rango [0,K-1] y los niveles empleados por la figura se encuentran en el rango [A,B] con A y B siendo los valores máximos y mínimos de intensidad respectivamente, se puede emplear la siguiente fórmula matemática que mapee los valores en el nuevo histograma:

.. _alfa:

.. figure:: estiramientoContrasteFormula.png
	:scale: 70%

	Fórmula de estiramiento de contraste

De esta forma, este procedimiento modifica el contraste de la imagen en general si sus niveles de grises no están distribuidos adecuadamente, aunque si ésta abarca varios valores en la escala de grises del histograma, esta técnica puede producir poca o ninguna diferencia con respecto a la imagen original. A continuación se puede observar un ejemplo que contrastado con la figura :num:`Fig. #librosoriginal`, tiene una mejora en el contraste de la misma:


.. figure:: estiramientoContrasteFormula.png
	:scale: 70%
 
	Ejemplo de estiramiento de contraste
 
Este tipo de técnica se emplea en aquellas imágenes con bajo contraste, o con poca iluminación, o con una configuración inapropiada del dispositivo de captura durante la adquisición de la misma, con el fin de lograr una mejor visualización de los detalles en ésta. 


Igualación de histograma(Histogram Equalization)
################################################

Este procedimiento consiste en normalizar los niveles de intensidad del histograma de imagen, de manera que éstos sigan una distribución uniforme, y luego realizar un estiramiento de contraste para los niveles abarquen la mayoría de los valores en la escala del histograma. Este procedimiento provoca que el histograma se estire en el eje de las abscisas y tiende a aplanarlo de manera que se adapte a la distribución.
Si se considera el caso para el histograma de imagen de una imagen con escala de grises, el primer paso consiste en realizar la normalización del histograma, obteniendo la función de densidad de probabilidad (PDF) de los niveles de gris, pf(k) para cada uno de los K niveles de intensidad.
La función de densidad de probabilidad trata los valores de los niveles de intensidad como cantidades aleatorias, y definiéndose la probabilidad pf(k) de un nivel k ocurriendo en una imagen como:

.. figure:: formulaNormalizacion.png
	:scale: 60%

	Fórmula de normalización de histograma



Donde la imagen digital tiene N x M pixeles,Hf(k) es el nivel de intensidad para un nivel k y k = 0,1,...,K-1. Éstas deben cumplir con la siguiente propiedad de sumatoria:


.. figure:: propiedadFormulaNormalizacion.png
	:scale: 60%

	Propiedad de sumatoria de los valores normalizados

En base a esta función, se define la función de distribución acumulada, Pf(r) para r niveles, con r= 0,1,...,K-1:


.. figure:: formulaDistribucionAcumulada.png
	:scale: 60%
 
	Función de distribución acumulada
 
Así para obtener un histograma igualado, primero se debe computar la función de distribución acumulada del histograma de imagen Pf(k) de la imagen digital, para cada uno de los niveles del histograma, lo que provocará que éste tienda a aplanarse gráficamente, y luego aplicar la función de estiramiento de contraste para cada uno de los elementos, con el fin de distribuirlos a lo largo de la escala. Esto provocará que la imagen final sea más impactante y visibles que la original, sin embargo este proceso no eliminará aquellos picos resultantes del proceso de cuantificación.A continuación se observa el proceso de igualación de histograma aplicado a la imagen de libros:


.. figure:: igualacionLibros.png
	:scale: 70%

	Imagen de libros y su histograma luego de aplicar la igualación

Así, este método se aplica cuando se desea una implementación simple que produzca una mejora automática en la imagen.  


Limitado de imagen(Image thresholding)
######################################

Esta técnica se emplea principalmente en imágenes con escala de grises, con el fin de abstraer información relevante respecto de los objetos en una imagen y optimizar el procesamiento y análisis subsecuente de la imagen. Este proceso consiste en, dada una imagen con K-1 niveles de gris, definir un limite entero T dentro del rango de niveles y comparar cada pixel con el límite T, y si la intensidad del pixel p(x,y) supera ese límite asignarle la intensidad 0, y en caso contrario asignarle el valor de intensidad 1.De esta forma, modificando el nivel del límite T se controla la abstracción de información que se generará en la imagen de salida, y dependiendo de las características del histograma de imagen, se abstraerá la cantidad de información relevante de ésta.
 
Este procedimiento es útil en imágenes que cuentan con histogramas bimodales, es decir, aquellos histogramas donde los promedios de brillo entre el fondo y los objetos de la imagen se encuentran claramente delimitados, como en aquellas imágenes que contienen objetos oscuros con fondo brillante, u objetos brillantes sobre un fondo oscuro. De esta forma, el objeto consiste en separar concisamente los objetos del fondo de la imagen, para luego etiquetarlos.


.. figure:: limiteImagen.png
    
	Límite de la imagen. En la izquierda se puede apreciar una imagen con niveles de intensidad correctamente delimitados, mientras que en la imagen de la derecha, se puede observar una imagen con un límite poco claro entre objetos y fondo.
    

Existen varias estrategias para la elección acerca de donde colocar el límite T: Si el histograma de imagen es bimodal, el límite se tiende a colocar entre medio de los modos de la imagen, como en la figura anterior. Sin embargo, esta aproximación tiene problemas si la imagen contiene multiples objetos de un brillo promedio diferente en un fondo uniforme(histograma multimodal), excluyéndose algunos objetos. También es difícil asignar un límite si el histograma es plano, conteniendo imágenes complejas, con variaciones de gris significativas, detalles, iluminación no uniforme, etc.


.. figure:: imagenMultimodal.png

	(a)Histograma multimodal que señala la dificultad de seleccionar un límite.(b) Histograma plano, para el que la selección de un límite es dificil o imposible.


Por otro lado, también se pueden emplear aproximaciones que usen un modelo estadístico sobre el histograma, con una función de distribución de probabilidad (pdf), donde se plantee la decisión de asignar 0 o 1 a cada pixel, como una prueba estadística. De esta manera, se puede seleccionar la función de distribución que mejor se adapte a las ubicaciones de los modos del histograma(picos de intensidad en éste), el ancho de cada modo y la decisión acerca de donde termina un modo y comienza otro; Pudiendo aplicarse un modelo probabilístico, dependiendo de la forma de los modos, como por ejemplo, una pdf Gaussiana. Esta alternativa puede producir resultados aceptables con respecto a la colocación de límites, sin embargo cualquier modelo probabilístico simple no tiene en cuenta factores importantes como la continuidad del fondo o de los objetos, apariencia visual, e iluminación no uniforme, por lo que un modelo estadístico no produciría resultados visuales tan eficientes, como los que generaría una persona manualmente.

Un ejemplo de aplicación de esta técnica, son las aplicaciones biomedicas, que permiten la iluminación de los objetos y el fondo, o imágenes microscópicas de una o múltiples células que contienen objetos brillantes sobre un fondo oscuro. 



Especificación(Histogram Matching o Specification)
##################################################

.. pag 150. Image processing 3rd edition Gonzales.

Este método consiste realizar un mapeo entre los valores de un histograma de imagen igualado y una función de transformación(con una función de densidad de probabilidad ), de forma que se puedan obtener los valores aproximados de la imagen de entrada, en el dominio de la transformación. El primer paso consiste en aplicar la técnica de igualación (descrita anteriormente) para obtener valores distribuidos uniformemente, y redondearlos al rango de [0, K-1], con K niveles. 
A continuación, se debe realizar la computación de la función de transformación G(), para cada uno de los q-niveles de intensidad, q=0,1,...,K-1. Los valores resultantes, son escalados y redondeados a sus valores más cercanos en el rango [0, K-1] y almacenados en una tabla.Esta fórmula define  una función de densidad de probabilidad pz(zi), que es la función de densidad de probabilidad que se desea que la imagen de salida adopte, sobre una variable aleatoria z:


.. figure:: formulaEspecificacionHistograma.png

	Fórmula de transformación G

Posteriormente, para cada valor de intensidad en cada pixel del histograma igualado, sk, se emplean los valores almacenados (luego de aplicar G()), para encontrar el valor más próximo zq a sk, dentro del dominio de los valores producidos por G(), de manera que G(zq) es el valor más cercano y almacenar este mapeo de s a z. Si ocurre que más de un valor de zq satisface la condición de sk (con un mapeo no único), se elige el valor más pequeño por convención. Finalemente, con estos valores obtenidos se produce el nuevo histograma de imagen con los zq valores obtenidos, empleando los mapeos almacenados con anterioridad.


.. figure:: ejemploEspecificacionHistograma.png

	Ejemplo de especificación de histograma. Se realiza la especificación de histograma de libros para que se aproxime a una "V" centrada en los niveles de gris y que se extiende a lo largo de la escala de grises, produciendo una imagen con un alto contraste. 


Operaciones aritméticas entre matrices
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Debido a que las imágenes se representan como matrices de números, pueden aplicarse operaciones aritméticas entre matrices que operen con los pixeles de éstas, siempre y cuando estas sean de la misma dimensión. Dadas dos imágenes con N x M pixeles y representándose los niveles de intensidad de éstas por medio de las funciones f(x,y) y g(x,y) con x=0,1,...,M-1 e y=0,1,...,N-1 y siendo M(x,y) la matriz resultante, las operaciones que se pueden aplicar a las matrices se pueden definir de la siguiente manera:

* Suma: M(x,y) = f(x,y) + g(x,y). Un ejemplo de aplicación de la operación de suma es la corrección de la imágenes que se encuentran con degradaciones aleatorias o ruido, debido a diversas factores en el ambiente. La técnica mas sencilla para eliminarlo, es el modelo de ruido aditivo, donde se considera que una imagen con ruido es la suma de una imagen original y una imagen con ruido, y se supone que el ruido en cada par de coordenadas no esta correlacionado y que la media de éste es cero. Así, se puede afirmar que al calcular un promedio de N imágenes con ruido, tomadas en una rápida sucesión y sin ruido en la escena, la media de este calculo tenderá a cero (una matriz N x M con valores cercanos a cero), lo que mejorará el grado de fidelidad con respecto a la imagen original por un factor de N. Sin embargo, si existen diferencias en la escena o, si existen dependencias entre las imágenes con ruido (en caso de que todas éstas sean casi idénticas), entonces la reducción de ruido será limitada.
  

.. figure:: ejemploSumaMatrices.png
	:scale: 70%
     
	Ejemplo de promediado de imágenes. La imagen de la izquierda es una imagen individual con ruido. La imagen del centro es un promedio de 4 imágenes. La imagen de la derecha es un promedio de 16 imágenes.
     
* Resta: M(x,y) = f(x,y) - g(x,y). La diferencia de imágenes es una técnica que se emplea para detectar cambios en imágenes tomadas sobre la misma escena en diferentes momentos, esto permite que se le pueda aplicar para el rastreo de objetos, reconocer el movimiento de objetos, para computar información 3-D del movimiento 2D, en cámaras de vigilancia, y campos de la astronomía donde los bajos niveles de frecuencia introducen ruido en el dispositivo de sensado. De esta forma, para detectar si existe un cambio de imagen significativo se realiza la sustracción de las mismas, y se analiza el histograma de imagen: Si los niveles de intensidad del histograma en el nivel n no son significativos, significa que no existe una diferencia considerable entre ambas; Por el contrario, si los valores en un intervalo de niveles n o en un nivel n es significativa, se podrá percibir que el histograma tendrá un nivel de intensidad(más brillo) en ese punto. A continuación, se puede observar el histograma luego de realizar la resta entre dos imágenes:
  
  .. figure:: diferenciaHistograma.png
  	:scale: 60%

	Las figuras (a) y (b) son las imágenes originales, la figura (c) es la imagen resultante de la diferencia y la figura (d) es su histograma asociado.
  

* Multiplicación: M(x,y)=f(x,y) * g(x,y). Este tipo de operación se emplea con el uso de una mascara para aislar regiones de interés(ROI) en la imagen final. Este proceso consiste en multiplicar una imagen por una mascara de imagen que tiene unos en la región de interés y cero en cualquier otra coordenada. Pueden existir más de una ROI en la máscara de imagen, con una forma arbitraria, aunque las formas rectangulares son usadas frecuentemente por la facilidad de implementación. En la siguiente imagen se puede observar el proceso de enmascarado de muelas en una imagen de rayos X:
  

  .. figure:: multiplicacionHistograma.png
  	:scale: 70%

	Multiplicación de histograma.La figura de la izquierda es la imagen original, la imagen del centro es la mascara de la ROI que aísla muelas (donde blanco corresponde a 1 y negro corresponde a 0), y la figura de la derecha es el producto entre estas dos imágenes.
  
  
* División: M(x,y) = f(x,y) / g(x,y). Este tipo de operación (en conjunto con la multiplicación) se emplea para la corrección de sombras, ya que si se tiene un sensor que captura una imagen g(x,y) que puede ser descompuesta en una imagen perfecta f(x,y) y una función de sombreado h(x,y) esto es: g(x,y) = f(x,y) * h(x,y) ;Entonces, se puede obtener la imagen ideal dividiendo: g(x,y)/h(x,y).



Operaciones geométricas de transformación
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Las operaciones geométricas modifican la relación espacial entre pixeles, realizando como primer paso la transformación espacial de las coordenadas de éstos a nuevas coordenadas en otro sistema de coordenadas, y posteriormente empleando la técnica de interpolación de intensidad, para asignar valores de intensidad a los pixeles transformados espacialmente. El esquema más empleado para definición de los métodos de la transformación de imágenes son las transformaciones afines (affine transformation) que son aquellas transformaciones que conservan la colinearidad entre puntos, lineas rectas y planos, es decir que todos aquellos puntos que yacen en una linea recta inicialmente aún lo hacen luego de aplicar la transformación, y las proporciones en las distancias entre los puntos, lo que significa que si un punto en una línea es el centro en la imagen digital de entrada, lo seguirá siendo en la imagen digital de salida. De esta forma, la combinación de estas transformaciones permite generar operaciones geométricas que actúan sobre cada pixel y producen una nueva imagen de salida.

Dada la coordenada de un pixel en una imagen digital de entrada (v,w) definida como una coordenada proyectada, es decir representado como un vector de tres valores (v,w,1) y siendo la coordenada para un pixel en el nuevo espacio (x,y), las transformaciones afines se pueden definir como una matriz de 3x3 T, donde dependiendo los valores definidos para los ente t11 y t32, se puede cambiar el tipo de transformación:


.. figure:: transformacionAfineMatriz.png

	Fórmula de la transformación afin T definida de manera genérica. 

En las siguientes secciones, se detallan las definiciones y efectos de las transformaciones afines principales.


Traslación
##########

La traslación es la operación mas sencilla y consiste en dada una imagen g(x,y), desplazar ésta en dirección horizontal y vertical, por medio de la suma de un valor tanto en el eje x como en el eje y.

.. figure:: traslacion1.png

	Definición matricial traslación

|
|

.. figure:: traslacion2.png

	Traslación gráficamente


Rotación
########

La rotación consiste en girar una imagen por un ángulo 0 relativo al eje x, empleando la siguiente matriz de transformación:

.. figure:: rotacion1.png

	Definición matricial de la rotación

|
|

.. figure:: rotacion2.png

	Rotación gráficamente


Escalado
########

El escalado consiste ampliar o reducir la escala de una imagen, empleando para ello los valores cx y cy como factores de escala del eje X y del eje Y respectivamente. Si los factores son menores a 1, la imagen se reducirá, mientras que si éstos son mayores a 1 la imagen aumentará su tamaño. Cuando se escala una imagen se modifica tanto la escala como la posición en el plano, por lo que si se desea volverla a posicionar sobre el origen se debe aplicar una traslación.


.. figure:: escalado1.png

	Definición matricial del escalado

|
|

.. figure:: escalado2.png

	Escalado gráficamente. Esta imagen fue escalada por un factor de escala de 1.4 en el eje X y por un factor de escala de 0.8 en el eje Y.

Un ejemplo de la aplicación de esta transformación es la técnica de zoom, donde simplemente se escalan cada coordenada de pixel por un valor para el eje X y otro para el eje Y, y luego se aplica la interpolación para obtener los niveles de  intensidad en la imagen resultante.



Inclinación o transvección(Shearing)
####################################

La inclinación o transvección, consiste en desplazar los puntos en un eje de manera lineal, por una cantidad proporcional a la coordenada en el eje perpendicular a ese. Esta transformación puede realizarse de manera horizontal sobre el eje X (en cuyo caso se desplaza cada punto de este eje por un valor proporcional a su coordenada en Y, quedando intactos los valores en y de cada punto),o de manera vertical sobre el eje Y (en este caso las líneas en verticales paralelas al eje Y se mantienen inalterables, modificándose las líneas paralelas al eje X). A continuación se muestra su definición matemática horizontal y verticalmente y un ejemplo de inclinación horizontal: 


.. figure:: inclinacion1.png

	Definición matricial de la inclinación

|
|

.. figure:: inclinacion2.png

	Inclinación horizontal gráficamente. 



Interpolación
#############

.. NOTA: Identacion h8

Una herramienta relacionada con las imágenes digitales es la interpolación, empleada en tareas como hacer zoom, reducción(shrinking), rotación y correcciones geométricas. Esta herramienta consiste en emplear datos conocidos de la imagen de entrada para estimar valores en coordenadas desconocidas. Por ejemplo, si se necesitara convertir una imagen a una escala mayor, la cantidad de pixeles y la correspondencia entre las intensidades diferirían por lo que sería necesario contar con un método que permita la asignación aproximada de intensidades. Un método para realizar ésto es asignar a cada pixel en la imagen mayor, el valor del pixel vecino más cercano si se superpone, esta imagen con la imagen de entrada, este método se conoce como interpolación de vecino más cercano.
Existen otros métodos para asignar intensidades que consideran más vecinos y, la forma en que consideran estos sigue alguna fórmula matemática, entre los que se encuentran la interpolación bilinear (donde se emplean los 4 vecinos mas cercanos para estimar la intensidad) y la interpolación bicubica (que toma los 16 vecinos más cercanos):

|

.. figure:: interpolacionBilinear.png
      
	Fórmula de interpolación bilinear
|
|

Donde v(x,y) es la intensidad del pixel en la coordenada(x,y), los coeficientes a,b,c y d se emplean para determinar los vecinos que de los que se obtendrá la intensidad. 


.. figure:: interpolacionBicubica.png
      
	Fórmula de interpolación bicubica
|


Técnicas de filtrado espacial
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. filtrado espacial(filtros de suavizado y sharpening)
.. Frecuencia y filtros de banda alta y baja(Introduction to digital image processing with MATLAB. pag 88)

El filtrado espacial consiste en rechazar aquellos elementos en una imagen que no son de interés y conservar aquellos necesarios para el proceso en que se aplica. El filtrado se basa en emplear un filtro(también llamado mascara, kernel, template y ventana o window) que se define como un conjunto de pixeles (o vecindario) sobre un pixel con una coordenada (x,y) y luego aplicar diferentes operaciones sobre ese conjunto de pixeles (pueden ser operaciones estadísticas para filtros no lineales, como la media,mediana,etc. u operaciones lógicas AND,OR,NOT,XOR), de manera que se obtenga un nuevo valor de intensidad para el pixel del centro en la coordenada (x,y).Generalmente, en la práctica el valor del pixel filtrado se asigna a una ubicación en una nueva imagen que se crea para mantener los resultados filtrados, de manera que el contenido de la imagen de entrada no cambie mientras se esta realizando el filtrado. La forma en que se organizan los pixeles que forman el filtro dependen del objetivo que se persigue al aplicar éste y se define generalmente por una regla que dependiendo de la cantidad de vecinos que se desea abarcar, aumenta esta cantidad manteniendo la forma original del filtro.


.. figure:: tiposFiltros.png
	:scale: 80%

	Tipos de filtros. (a) Filtros de una sola dimensión con una formula de fila ROW=2P + 1 y de columna COL=2P + 1 para pixeles P=1,2. (b) Filtros de dos dimensiones con formulas cuadrado SQUARE = (2P + 1)^² y cruz CROSS = 4P + 1, para P=1,2.


De esta forma, el proceso de filtrado consiste en realizar un desplazamiento de la máscara de filtrado por cada uno de los pixeles de ésta, y obtener el valor del pixel central producto de la operación efectuada; Matemáticamente este proceso se puede definir como: Dado un pixel con coordenada (x,y) en la imagen de entrada de tamaño M x N, variando x,y en el rango de los pixeles de la imagen, una máscara de m x n, con una mascara de filtrado rectangular con m= 2a + 1, n = 2b + 1 y, siendo los coeficientes de filtrado los valores wi que se aplican a las intensidades f(x,y)  de cada pixel de la imagen:


.. figure:: defMatematicaFiltrado.png
 
	Definición matemática de la operación de filtrado


La mascara de filtrado requiere que se especifiquen coeficientes de filtrado para cada una de las intensidades del filtrado, lo que puede hacerse especificando valores  iguales para todos los pixeles de la mascara,estar estos ponderados para asignar mas prioridad a ciertos pixeles en la imagen, o cuando se tiene una función estadística obtener la mascara de filtrado en base a ésta, aplicando la formula al vecindario de un pixel y obteniendo como salida, el nivel de intensidad del pixel en la imagen de salida. Con ésta ultima aproximación, solamente se requiere especificar la fórmula matemática y las dimensiones del vecindario para aplicarla. Un ejemplo de esta ultima aproximación, es aplicar la distribución de Gauss en un pixel, donde se considera la varianza de los pixeles y las coordenadas del pixel central (x,y), de forma que la aplicación de la mascara de filtrado consiste en tomar muestras y aplicar la formula en distintas ubicaciones:


.. figure:: formulaGauss.png
	:scale: 60%

	Fórmula de Gauss aplicada a un pixel de imagen.

|
|

.. figure:: filtradoEspacialEsquema.png

	Representación gráfica de los elementos considerados para el filtrado espacial


Existen dos tipos de filtros según el tipo de operación que se realiza en ellos: Los filtros lineales que son aquellos donde la operación que se aplica sobre los pixeles de una imagen es una operación lineal, y los filtros no lineales donde se aplican operaciones no lineales sobre éstos.Una operación lineal es aquella donde se cumplen las propiedades de homogeneidad y adición para una imagen de entada f(x,y) y una imagen de salida g(x,y):

* La homogeneidad ocurre cuando al multiplicar la salida de un operador aplicado a la imagen produce el mismo resultado, que multiplicar esa constante en la imagen de entrada y luego aplicar el operador. 
* La adición que consiste en que la salida de una operación lineal a la suma de dos entradas, es lo mismo que aplicar la operación lineal a las entradas y luego realizar la suma de las mismas. 


Los filtros pueden ser aplicados tanto en el dominio espacial o en el dominio de las frecuencias, abarcando un diverso rango de aplicaciones, aunque principalmente se destacan: La mejora de la imagen, donde se intenta mejorar la calidad de imagen en algún aspecto para interpretación artificial o humana por medio del suavizado de imagen; Y la restauración de imágenes, donde se intenta recuperar información de una imagen degradada con conocimiento del proceso de degradado, empleando filtros que se pueden aplicar en el dominio espacial y en el dominio de las frecuencias.

El suavizado de imagen, aplicado en técnicas de pre-procesamiento de imagen (como remover detalles antes de la segmentación de objetos), es un ejemplo del uso tanto de filtros lineales como no lineales, ya que durante esta tarea se busca reducir el ruido y en suavizar la imagen (blurring). Un ejemplo de filtro lineal para la reducción de ruido, es aplicar el promediado de los pixeles vecinos definidos por la máscara en una imagen de entrada. Debido a que el ruido en una imagen ocurre cuando existen transiciones abruptas en niveles de intensidad entre pixeles vecinos, el promediado provoca una disminución en la diferencia de niveles, sin embargo, debido a que los contornos de las figuras se caracterizan por ésto, también produce que los bordes se vean poco nítidos. Otras aplicaciones de este tipo de filtro de suavizado, es reducir el detalle irrelevante, o la disminución de contornos falsos producto de niveles de intensidad insuficientes. A continuación, se puede observar el efecto de suavizado empleando el filtro de promedio de vecinos:


.. figure:: ejemploSuavizadoImagen.png

	Efecto de suavizado. La imagen original se sitúa en la parte superior izquierda. La imagen superior derecha tiene un filtro rectangular con una mascara de m=3. La imagen inferior izquierda con un filtro rectangular con m=5. La imagen inferior derecha tiene un filtro rectangular con m=9.


Alternativamente, se pueden emplear filtros no lineales estadísticos para el suavizado de imagen, cuya respuesta se basa en ordenar los pixeles contenidos en el área de la imagen abarcada por el filtro, y reemplazar el valor del pixel del centro con el valor determinado por el resultado del ordenamiento.Existen varios tipos de filtros para suavizado que se basan en distintos valores (maximo,minimo), no obstante el ejemplo más relevante es el filtro que emplea la mediana (valor del conjunto para el cual la mitad de los valores son mayores o iguales a la misma y la otra mitad son menores o iguales) de los valores de intensidad en el pixel (incluyendo el valor del pixel en el cálculo), donde se lo obtiene y luego se asigna este valor como el valor de intensidad del pixel de salida. Este tipo de filtro es empleado debido a que produce excelentes resultados para la reducción de ruido aleatorio, con respecto filtros lineales del mismo tamaño. A continuación se destaca el efecto del suavizado de imagen empleando un filtro de mediana y un filtro de promediado lineal:


.. figure:: ejemploFiltroMediana.png

	Filtro de mediana vs filtro lineal. La imagen izquierda es un circuito electrónico con ruido. La imagen central es el resultado de la aplicación de un filtro lineal de 3x3. La imagen derecha es el resultado de aplicar un filtro no lineal de mediana de 3x3.


.. Filtros lineales (obedecen a una operacion lineal) y filtros no lineales (estadisticos. seccion 5.3 image processing gonzales 3rd edition).

.. Filtros lineales --> Correlación y convolucion.
.. Dos conceptos asociados a la forma de aplicar la máscara son el de correlación y convolución, donde la correlación consiste en despalazar la mascara de filtrado sobre la imagen y computar la operación, mientras que la convolución consiste en rotar 180º la máscara y luego realizar la correlación.  



Técnicas sobre el dominio de las transformaciones
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Las operaciones que se ejecutan sobre el dominio de las transformaciones hacen uso de la transformada de Fourier para llevar las funciones al dominio de las frecuencias, efectuar operaciones sobre este dominio y finalmente, obtener la imagen de salida aplicando la función inversa a esta transformación.La transformada de Fourier es una técnica altamente empleada en el procesamiento de imágenes, ya que permiten realizar operaciones que de alta complejidad que requerirían un alto tiempo de procesamiento si no se empleara esta técnica, y realizar tareas asociadas al procesamiento imagen de manera más eficiente que empleando filtros lineales (cuando estos son de grandes dimensiones). Esta técnica se emplea en un amplio espectro de tareas tales como la mejora de video, restauración, compresión, segmentación y métodos que emplean la técnica de wavelets. La transformada de Fourier se desprende de las series de Fourier, propuestas por el matemático Frances Jean Baptiste Joseph Fourier 1822 para ser aplicadas en el campo del flujo del calor, donde se expresa que sin importar lo compleja que sea una función, si ésta es periódica se puede expresar matemáticamente como la suma de senos y cosenos de diferentes frecuencias, multiplicados cada uno por un coeficiente diferente. De esta forma, la transformada de Fourier(FT) extiende este concepto afirmando que, aquellas funciones cuya área debajo de la curva es finita y no necesariamente son periódicas, puede expresarse para las variables continuas, como la integral de los senos y/o cosenos multiplicados por una función de ponderación; Pudiendo ser ésta, reconstruida o recuperada completamente por el proceso inverso, sin pérdida de información. Esta característica permite trabajar sobre el dominio de Fourier y luego retornar al dominio espacial de una imagen sin perder información.


.. figure:: esquemaDominioFrecuencias.png
	:scale: 70%

	Esquema del dominio de las transformaciones


Debido a que para representar una imagen digital se debe trabajar con valores discretos, la transformada de Fourier se debe definir de manera discreta (DFT Discrete Fourier Transform), donde ésta se define como una función F(u,v) sobre los valores (u,v) que representan las frecuencias con que se representará la imagen definiendo u como la frecuencia de oscilación a lo largo del eje X y la frecuencia de oscilación a lo largo del eje Y(expresadas en ciclos por pixel) que se emplearan para representar la imagen definida en el dominio dominio espacial sobre éste dominio: 


.. figure:: formulaFTD.png
	:scale: 60%

	Fórmula de la Transformada de Fourier Discreta

Además, esta función toma valores discretos x,y que son las coordenadas de los pixeles para una imagen digital de M x N, con u=0,1,2,...,M-1, v=0,1,2,...,N-1 y, su inversa, que permite obtener la imagen en el dominio espacial partiendo de la matriz de frecuencias, se define:  

.. figure:: formulaIFTD.png
	:scale: 60%

	Formula de la Transformada  de Fourier Inversa

.. Teorema de la convolución. Propiedades, matriz de angulos de fase, de espectro de frecuencias y de potencias.

Esta formula cuenta con distintas propiedades entre las que se destacan:

* Magnitud o espectro(Espectro de frecuencias): El espectro consiste en aplicar para cada uno de los elementos de la frecuencia de la matriz la siguiente formula:
  
.. figure:: formulaEspectro.png
	:scale: 60%

	Fórmula para el calculo del espectro

De manera que se obtenga una matriz de magnitud de frecuencias de la imagen del mismo tamaño de la imagen digital M x N (con la amplitud de las mismas), donde los vectores se representan con números complejos C= R + jI, correspondiendo R a la parte real del mismo y, siendo I la parte imaginaria (donde j es la raíz cuadrada de -1) y donde el conjunto de números reales se representan como números complejos con I=0.
Los componentes del espectro de la DFT determinan las amplitudes de las sinusoidales que componen la imagen, almacenando información acerca de las intensidades en la imagen, por lo que en cualquier frecuencia dada de una imagen, una gran amplitud implica una mayor relevancia de la onda sinusoidal para esa frecuencia; Mientras que si se cuenta con una pequeña amplitud, implica en menor medida la presencia de una onda sinusoidal en esa frecuencia.


* Angulo de fase (Fase). El ángulo de fase para cada elemento de la matriz se obtiene por medio de la siguiente fórmula:
  
.. figure:: formulaAnguloFase.png
	:scale: 60%

	Fórmula para el cálculo del ángulo de fase

El angulo de fase o fase, es una medida del desplazamiento de varias ondas sinusoidales con respecto al origen, por lo que este arreglo contiene los ángulos que contienen información respecto de donde los objetos se encuentran localizados en la imagen.




* Espectro potencia. El espectro potencia se calcula para cada elemento de la imagen con la siguiente fórmula:
  
.. figure:: formulaPotencia.png
	:scale: 60%

	Fórmula para el espectro potencia


* Simetría. La simetría con respecto a la transformada de Fourier discreta, enuncia que la magnitud del espectro es simétrica par respecto del punto central por lo que se cumple la siguiente igualdad:
  
.. figure:: formulaSimetrica.png
	:scale: 60%

	Formula simétrica par en el espectro de magnitud

Mientras que el angulo de fase es simétrica impar con respecto al origen, lo que significa que se cumple la siguiente igualdad:


.. figure:: formulaAsimetrica.png
	:scale: 60%

   	Formula asimétrica par en la fase


* Traslación. La propiedad de traslación implica que al multiplicar la imagen f(x,y) por la parte exponencial de la transformada de Fourier en coordenadas (u0,v0), provoca un desplazamiento de la transformada al punto (u0,v0), y en consecuencia, multiplicar F(u,v) por el negativo de esa exponencial cambia el origen de f(x,y) hacia (x0,y0).
  
  .. figure:: formulaTraslacionDFT.png
  	:scale: 60%
  
	Formulas de traslación DFT. 
  
* Rotación. La rotación implica que al multiplicar la imagen en el dominio espacial f(x,y) por un angulo A, rota la función en el dominio de las frecuencias F(u,v) por el mismo ángulo. Del mismo modo, rotar F(u,v) por A, rota la imagen en el dominio espacial f(x,y) por el mismo ángulo.  
  

* Teorema de la convolución. La convolución (representada por **) se emplea en el filtrado de imágenes, y consiste en rotar el filtro 180º y luego aplicarlo pixel a pixel por la imagen digital de entrada. De esta forma, la convolución en el dominio espacial entre una imagen f(x,y) y una transformación g(x,y) equivale a realizar la convolución en el dominio de las frecuencias de las funciones F(x,y) y H(x,y) respectivamente.

	.. math::  f(x,y)**g(x,y) <---> F(u,v)*H(u,v)
		:label: formulaConvolucion1

De la misma forma, el producto en el dominio espacial de una imagen f(x,y) y una transformación g(x,y), es equivalente a aplicar la convolución entre las funciones del dominio de frecuencias F(x,y) y G(x,y).
	
	.. math::  f(x,y)*g(x,y) <---> F(u,v)**H(u,v)
		:label: formulaConvolucion1


Cuando se quiere convertir una imagen digital al dominio de las frecuencias, como primera medida se debe aplicar una función de centrado del espectro, multiplicando cada uno de las coordenadas de la imagen por (-1)^x+y, esto permite que el espectro de la imagen este centrado;Adicionalmente, se puede aplicar una transformación logarítmica (1 + log(|F(u,v)|)) con el fin de aumentar la intensidad de los valores de la matriz de magnitud. Luego, se procede a aplicar la fórmula de Fourier discreta para cada una de las coordenadas en el dominio de la imagen digital con M x N pixeles, para obtener las matrices de magnitud y de fase, que tendrán las mismas dimensiones que la imagen de entrada. Aunque estas no contienen fácilmente asociable a las coordenadas de la imagen digital, se pueden visualizar igual que las anteriores:


.. figure:: graficoMagnitudFourier.png

	Gráficos correspondientes a un rectangulo y su matriz de magnitud. Imagen superior derecha: Imagen original de un rectangulo. Imagen superior izquierda: Magnitud con las frecuencias. Imagen inferior izquierda: Imagen original rotada. Imagen inferior derecha: Efecto de la rotación en el dominio de las frecuencias.


Debido a que los valores de frecuencia F(u,v) son modificaciones de los valores de intensidad de la imagen con términos exponenciales, la correspondencia entre objetos y sus frecuencias es compleja, sin embargo observando el gráfico anterior se puede observar que la frecuencia esta directamente asociada a las tasas de cambios de intensidad en el dominio espacial, por lo que se las puede relacionar con los patrones de intensidad de una imagen. De esta forma, aquellos componentes con una frecuencia que varíen más lentamente son proporcionales al promedio de valores de frecuencia y se encuentran localizados en el centro del gráfico, y a medida que se desplazan los puntos desde este origen, las bajas frecuencias representan componentes cuya variación de intensidad es lenta en la imagen, pudiendo corresponderse éstos por ejemplo con las variaciones asociadas a paredes o pisos; Mientras que aquellas frecuencias que se encuentran más alejadas del origen, y poseen un valor más alto, se corresponden con a cambios de intensidad más altos en la imagen, como los bordes de los objetos.

Un ejemplo de aplicación del proceso de la transformada Fourier es el filtrado de elementos durante el suavizado de imagen, donde dada una imagen f(x,y) de M x N pixeles que necesita ser de un tamaño mayor para ser filtrada, se debe rellenar esta imagen con ceros con los pixeles P = 2*M, Q=2*N (por lo que la imagen pasa a tener PxQ pixeles). A continuación, se procede a centrar la transformación multiplicando por (-1)^x+y y a computar TFD de esta matriz F(u,v) y se aplica el filtro H(u,v) de tamaño P x Q a la matriz de intensidad G(u,v)= H(u,v)*F(u,v). Finalmente, se procede a obtener la imagen g(x,y) en el domino  espacial, aplicando la función inversa de la transformada de Fourier y centrándola de nuevo con: g(x,y) = [IFTD(G(u,v))](-1)^x+y, y se recorta esta imagen extrayendo la región M x N de la imagen. En la siguiente figura se puede apreciar el proceso de transformacion, ubicándose las figuras de manera descendente de izquierda a derecha:


.. figure:: ejemploTFDCompleto.png

	Ejemplo de transformada de Fourier aplicada al suavizado de imagen.




Tipos de imágenes digitales
+++++++++++++++++++++++++++

Existen distintos tipos de imágenes digitales según la metodología seleccionada para representar la intensidad, entre los que se destacan los siguientes tipos: Imágenes binarias, imágenes por escalas de grises, imágenes a color e imágenes indexadas.



Imágenes por escala de grises
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Este tipo de imágenes se representa por medio de un conjunto de valores, que abarcan distintas tonalidades de grises desde blanco hasta negro, representándose cada pixel con 8 bits.
|

.. figure:: greyscaleImg.png
	:scale: 50%
   
	Representación de imagen en escala de grises


Existen distintos tipos de operaciones que pueden realizarse sobre imágenes con escalas de grises, aunque se pueden clasificar de manera general en: Operaciones de puntos, operaciones aritméticas y operaciones geométricas.
Las operaciones de puntos son aplicadas a los pixeles individuales de una imagen, por lo que las interacciones y las dependencias entre pixeles vecinos no son consideradas, ni las operaciones que toman un conjunto de pixeles, sino que se basan en el procesamiento de las intensidades de los pixeles. Por lo tanto, este tipo de operación no altera la posición de los objetos en la imagen, sino que modifican la apariencia general de la imagen, cambiando la distribución de grises de la misma ,obteniendo el negativo o, desplazando los niveles de grises para aclarar la imagen.


Las operaciones aritméticas se realizan entre imágenes de las mismas dimensiones espaciales, este tipo de operaciones es similar  a las operaciones por puntos debido a que la información espacial no es considerada, sino que la información se comparte entre imágenes y  se ejecutan pixel por pixel. Este tipo de operaciones se emplea para para la reducción del ruido en la imagen (distorciones aleatorias en la imagen producidas por radiación antes de capturar la misma o por fallos eléctricos en el dispositivo de sensado ), donde se realiza un promediado de las tonalidades de grises de un conjunto de frames y el resultado final es una imagen cuyo nivel de ruido ha sido reducido considerablemente.
Otra área donde se emplean operaciones de éste tipo es en la detección de movimiento en sistemas de vigilancia, o en sistemas automatizados de inspección visual, donde se realiza la diferencia entre las matrices que representan las imágenes y luego se computa el histograma de imagen, que mostrará variaciones importantes en el intensidad (valores de brillo mayores) si cambios significativos han ocurrido entre dos frames.

Finalmente, las operaciones geométricas son operaciones complementarias a las operaciones por puntos debido a que no modifican los valores de los niveles de gris, sino que modifican la imagen modificando cambiando las posiciones de los elementos de la imagen. Este tipo de operaciones se emplea para realizar la rotación, traslación o zoom-in o zoom-out en la imagen.


Imágenes binarias
~~~~~~~~~~~~~~~~~

En este tipo de imagen digital la intensidad de los pixeles sólo puede asumir dos valores 0 o 1, por lo que sólo se requiere un bit para su representación y los objetos se representan como una secuencia de 1 conectados, siendo éstas las que requieren menos espacio y tiempo de almacenamiento. Estas imágenes contienen suficiente información respecto de los objetos en la imagen y permiten que éstos se reconozcan fácilmente.
Este tipo de imágenes se emplean en distintos tipos de aplicaciones de visión por computadora, como el reconocimiento de objetos, el rastreo,etc. aunque su aplicabilidad es limitada debido al contenido limitado de información que brindan.
Las imágenes binarias surgen de una variedad de fuentes, generalmente son creadas por medio del procesamiento de imágenes de escala de grises, aunque algunos tipos de sensores entregan una imagen binaria como salida, como los dispositivos que se emplean para obtener dibujos o texto escrito a mano con un pad resistivo, un lápiz de luz. Generalmente estos dispositivos, inicializan todas las coordenadas de la imagen binaria en cero, y al detectar la presión o un cambio de resistencia, o luz sensada en una coordenada, entonces se le asigna a la misma el valor 1.Ejemplos de imágenes binarias, son los dibujos de líneas, texto escrito o impreso, siluetas, huellas digitales,o planos empleados por arquitectos.
|

.. figure:: imagenBinaria.png

	Imagen binaria




Imágenes a color
~~~~~~~~~~~~~~~~

Con la finalidad de incluir el color en el procesamiento de imágenes, se debe emplear un modelo de color que permita la especificación de las intensidades de los colores en un sistema de coordenadas y un rango de valores dentro de ese sistema de coordenadas, donde cada color sea representado por un único valor. Debido a la variedad de campos de aplicación del color, existen diferentes esquemas de representación según el objetivo, entre los que se encuentran:

* RGB(Red,Green,Blue). Emplea diversas combinaciones de colores primarios(normalizados entre [0,1] o sino valores en el rango 0-255) para la representación de colores en imágenes. Este modelo es utilizado principalmente por monitores a color y cámaras de video y para la manipulación y generación de imágenes digitales.
* CMY(Cyan,Magenta,Amarillo) y CMYK(Cyan,Magenta,Amarillo,Negro). Hace uso de los colores secundarios para representar el color, y es empleado para la impresión de imágenes color, realizándose una conversión interna del esquema RGB a CMY/K.
* HSI(Tonalidad,Saturación,Intensidad). La tonalidad es un valor que describe el nivel de pureza de un color (rojo,verde o azul) percibido por un observador, la saturación brinda una medida del grado en que la luz blanca esta mezclado con la tonalidad de un color y, el brillo es una medida subjetiva que abarca la noción de la intensidad en imágenes sin color.Este modelo hace uso de estas características y además permite desacoplar la información de color y el componente de intensidad.


El esquema empleado para la representación de imágenes digitales es RGB donde se emplea un vector para representar la composición de colores, de manera que cada pixel tenga asociadas las combinaciones correspondientes tres colores primarios (RGB), utilizando para cada color una representación de 8 bits.Por lo tanto, una imagen a color emplea 24 bits por cada pixel, necesitándose un total de (2^8)^3 = 16,777,216 valores posibles de color.
De esta forma, para una imagen con N x M elementos, existe un vector que contiene la intensidad asociada a cada color primario, que se corresponde con las coordenadas (x,y) de la siguiente forma:

|
|
.. figure:: formulaVectorColor.png
	:scale: 60%

	Vector de color para una coordenada en la imagen
|


Por lo tanto, la representación de una imagen de colores se reduce a realizar combinaciones entre el vector RGB de cada pixel: 

|
|
.. figure:: imagenColor.png
	:scale: 60%

	Representación de una imagen digital a color
|
|

.. figure:: imagenColorvsGreyScale.png

	Representaciones de imagen en escala de grises vs imagen de color
|

Existen varias aproximaciones para afrontar el procesamiento de imágenes de color, aunque se pueden clasificar en 2 grupos generales: Aquellas aproximaciones que procesan cada componente de la imagen individualmente, para luego formar la imagen de salida con éstos; Y aquellas aproximaciones que trabajan con los colores de los pixeles en la imagen directamente. Este tipo de imágenes pueden ser procesadas con algunos los tipos de técnicas que se emplean con las imágenes de escala de grises, mientras que algunas tienen que ser modificadas para ser aplicadas sobre las bandas de color individuales.


Imágenes indexadas	
~~~~~~~~~~~~~~~~~~

En general las imágenes indexadas solo emplean un subconjunto pequeño de los 16 millones de colores, por lo que para mejorar la eficiencia de almacenamiento, la imagen puede tener asociado un mapa de color o paleta de colores, la cual es solamente un listado de todos los colores en la imagen. Así, cada pixel tiene un valor que no da su color, como en la imagen RGB, sino que es un índice al color en el mapa.
Este tipo de imágenes digitales, se emplea en algunos formatos donde la cantidad de colores permitidos para una imagen es de 56 colores o menos, como en el formato GIF.
|

.. figure:: imagenIndexada.png
	:scale: 50%

	Imagen de color indexada
|


Procesamiento de imágenes
+++++++++++++++++++++++++

Debido a que el procesamiento de imágenes abarca varios tipos de imágenes, comprendidas a lo largo de todo el espectro electromagnético, éste tiende a solaparse con otras áreas como el análisis de imágenes,basado en la extracción de información de utilidad desde la imagen, y la visión artificial, que es un área de la inteligencia artificial cuyo objetivo es lograr que una computadora adquiera conocimiento y pueda efectuar decisiones, basada en imágenes o video de entrada.
Así,el procesamiento de imágenes digitales, es un conjunto de técnicas que toman una imagen como entrada y, por medio de una computadora, producen una imagen de salida con el objetivo de extraer información y reconocer objetos en ésta.


Las herramientas y técnicas definidas anteriormente, se emplean en distintos tipos de operaciones que se pueden clasificar según:
* El nivel de abstracción
* El objetivo perseguido 

Dependiendo del nivel de abstracción los procedimientos de procesamiento de imágenes se pueden clasificar en distintos tipos:

* Procesos de bajo nivel, que aceptan imagen como entrada, y ejecuta operaciones primitivas sobre ésta como la reducción de ruido, mejora del contraste y aplicación de filtros sobre la imagen para mejorar alguna característica (como aumentar el brillo entre áreas oscuras y con brillo), y producen una imagen modificada como salida.
* Procesos de nivel medio, que abarcan tareas como la segmentación (división de la imagen en partes), descripción de dichos objetos para reducirlos a una forma aceptable para el procesamiento por computadora, y el reconocimiento de objetos individuales(o clasificación de objetos). Estos procesos se caracterizan por el hecho de que las entradas son generalmente imágenes, pero sus atributos son atributos extraídos de una imagen, tales como: bordes, contornos, objetos individuales,etc.
* Procesos de alto nivel, que involucran  generar conocimiento a partir de éstos objetos ensamblados (empleando mecanismos de machine learning) y efectuar operaciones relacionadas con el análisis de imágenes y, algunas operaciones relacionadas con el campo de visión por computadora.
 
Alternativamente,los tipos de operaciones en el procesamiento de imagen según el objetivo que se persiga se pueden clasificar en:

.. pagina 49 gonzales, image processing.

* Aplicación de filtros y mejora la imagen. Estas técnicas buscan manipular la imagen, de manera que el resultado sea mas adaptable que la original para una aplicación específica. Esto se hace con el fin de recuperar detalles que no se visualizan debido al bajo nivel de brillo, o simplemente subrayar ciertas características de interés en una imagen. Un ejemplo de este tipo de operaciones es cuando se aumenta el contraste para mejorar visualmente los objetos que se perciben en la imagen.

* Restauración y reconstrucción de la imagen. Este tipo busca mejorar la apariencia la imagen, sin embargo a diferencia de la mejora de imagen, esta técnica es objetiva debido a que se basan en modelos probabilísticos de degradación de imagen, mientras que la primera se basa en la subjetividad del observador para establecer una mejora adecuada. La restauración intenta recuperar una imagen que ha sido degradada empleando un conocimiento previo del fenómeno de degradación, por lo que estos procesos se encuentran orientados hacia el modelado de la degradación y la aplicación del proceso inverso, para recuperar la imagen original.

   
* Wavelets. Las Wavelets son un conjunto transformaciones que forman parte del área de procesamiento de señales e imágenes denominado teoría de multiresolución, que abarca un conjunto de técnicas, incluyendo la división de bandas de una señal (subbanding), filtrado de voz digital y representación piramidal de una imagen. Esta rama se relaciona con la representación de imágenes (o señales) en más de una resolución, con el fin de obtener a una resolución específica, características que no se podrían identificar en otra resolución. Este tipo de herramienta es utilizada ampliamente para la compresión y la representación piramidal de una imagen. Esta última fue originalmente aplicada para la visión artificial y la compresión de imágenes, y consiste en subdivide subdividir una imagen con el fin de obtener una colección de imágenes de menor resolución organizadas en forma de imagen para su posterior procesamiento.
  
.. figure:: piramideImagen.png

	Representación piramidal para un arreglo de imagen de 2-Dimensiones de N x N
|


* Compresión.El objetivo de la compresión (o coding) es representar una imagen digital con la cantidad mínima de bits sin pérdida de información, persiguiendo así, la aceleración de la velocidad de transmición y reducción del ancho de banda necesaria para transmitir las mismas y la minimización del espacio requerido para almacenarlas, manteniendo a la vez en la fidelidad de la misma. La compresión es posible porque existe una redundancia presente en las imágenes, que es proporcional a la cantidad de correlación entre las muestras de datos. Por ejemplo, en imágenes estáticas existe un alto grado de correlación en los alrededores de un pixel, mientras que en los videos ésta se encuentra presente entre frames sucesivos del mismo. De esta forma para lograr un grado eficiente de compresión, estos métodos intentan remover los datos redundantes como así también, aquellos que se perciben pero son irrelevantes, produciendo que las imágenes de entrada y salida sean visualmente iguales, y no necesariamente numéricamente iguales.Las técnicas de compresión de las imágenes,se emplean frecuentemente en la extensión de las mismas, que a la vez representan el estándar seguido para la compresión como JPEG (Joint Photographic Experts Group).
  

.. AGREGAR INFO A PROC. MORFOLOGICO EN IMAGE PROCESSING GONZALES. PAG. 649.

* Procesamiento morfológico. La morfología se relaciona con la forma y las relaciones entre las partes de una imagen. El procesamiento morfológico consiste en aquellas herramientas que permiten extraer componentes de la imagen que son útiles en la representación y descripción de la forma. El procesamiento morfológico utiliza los mecanismos de la teoría de conjuntos y considera cada uno de los elementos que componen una imagen digital como conjuntos. Por lo tanto, si se emplea una imagen binaria cada pixel con coordenada (x,y) se define como un conjunto de dos dimensiones que representa el pixel blanco o negro de la misma, mientras que si se emplea una imagen con escala de grises, los dos primeros elementos del conjunto representan las coordenadas y el tercero corresponde al nivel de intensidad, e imágenes con distintos modelos de color se representan con conjuntos de mayores dimensiones.

Así, el procesamiento morfológico consiste en aplicar a las imágenes representadas por conjuntos elementos de estructurado (ESs), que son pequeños conjuntos o sub-imágenes, que pueden adoptar distintas formas(aunque se rellenan con elementos para que adopten formas rectangulares),utilizadas con el fin de probar una imagen bajo estudio para propiedades de interés. A continuación se pueden observar distintos ES, con un origen se encuentra marcado por un punto negro, aunque si éste no se encuentra marcado se considera que es el centro del elemento de estructurado:


.. figure:: ESProcMorfologico.png

	Ejemplos de ES de procesamiento morfológico 
 

Por lo tanto el procesamiento morfológico, consiste en crear un nuevo conjunto que representará la imagen de salida, aplicando el origen de los elementos de estructurado B a cada uno de los pixeles de la imagen A, conservando el pixel que esta en el origen, en aquellos casos en los que todos los elementos del conjunto B pertenezcan a la vez al conjunto A. Esto quiere decir, que al aplicar B sobre A, se conserva el elemento en el origen solo si todos los pixeles de B se encuentran superpuestos con pixeles de A que representan un objeto.En la siguiente figura se puede observar un ejemplo donde para la imagen A con un objeto sombreado, y un ES denominado B, B se aplica la imagen y se genera una nueva imagen con el objeto original reducido en tamaño:

.. figure:: ejemploProcMorfologico.png
	:scale: 60%

	Ejemplo de procesamiento morfológico. En la fila superior se observa la imagen y el ES asociado.En la parte inferior-izquierda se visualiza la imagen original, en la parte inferior-central se encuentra el ES, ampliado para adoptar una forma rectangular (donde la parte sombreada representa los pixeles de interés que deben tenerse en cuenta con respecto a la pertenencia), y la parte inferior-derecha representa el objeto sombreado luego de haber aplicado el ES.  
 
Las operaciones morfológicas que se aplican en una imagen, emplean los elementos de estructurado en conjunto con las propiedades de reflección y de traslación, y operaciones primitivas de erosión y dilatación. La propiedad de reflección consiste en reemplazar las coordenadas de la imagen por sus opuestas modificando el signo de cada uno de los elementos del conjunto. Mientras que la traslación consiste en desplazar los elementos del conjunto por un valor z, cuya dimensión dependerá de la cantidad de elementos del conjunto.

.. figure:: formulaReflexionMorfologia.png
	:scale: 50%

	Fórmula de reflexión para un conjunto B.
|
|

.. figure:: formulaTraslacionMorfologia.png
	:scale: 50%

	Fórmula de traslación para un conjunto B para un valor z.  


Por una lado la erosión de una imagen A por B dentro de un espacio Z^2, es el conjunto de todos los puntos z tales que B, trasladado por z esta contenido en A, es decir,que elimina todos aquellos puntos que desplazados por z estan localizados dentro de A. Esto en una imagen binaria hace mas finos los objetos de la imagen, removiendo de la misma aquellos elementos que son mas pequeños que el elemento de estructurado.  

.. figure:: formulaErosionMorfologia.png
	:scale: 50%

	Fórmula de erosión

Por otro lado, la dilatación de una imagen A por B dentro de un espacio Z^2, consiste en realizar la reflección de la imagen alrededor del origen de ésta y luego aplicar la traslación a la reflección por un valor z. De esta manera, la dilatación consiste en mantener aquellos z para los que la reflexión de B y los valores de A se superponen por al menos un elemento. Esta técnica a diferencia de la erosión, provoca que los objetos se vuelvan más gruesos (crezcan de grosor), dependiendo la medida en que estos se modificarán según la forma del elemento de estructurado aplicado a la imagen.


.. figure:: formulaDilatacionMorfologia.png
	:scale: 50%

	Fórmula de dilatación


.. NOTA: La transformación hit-or-miss que es empleada para la detección de objetos basados en su forma, consiste en aplicar la erosión a una imagen A por un objeto B1, y aplicar la erosión al complemento de A del fondo del objeto B2, y luego si existe una intersección entre estos dos conjuntos resultantes, el objeto se encuentra contenido en A. Esta técnica se basa en afirmar que dos o mas objetos son distintos si forman un conjunto disjunto la aplicación de la erosion de A por B1 y B2, requiriendo que el objeto tenga al menos un pixel de grosor en la imagen. Esto es empleado en algunas aplicaciones donde existe interés en detectar patrones de 1s y 0s en imagenes binarias, en cuyo caso el borde el objeto no se requiere, por lo que esta operación se transforma en una erosión entre A y B. 

.. LINK UTIL --> 
.. https://www.slideshare.net/LalSaid/07-b-morphological-orperations

Por lo tanto, las operaciones principales asociadas este tipo de procesamiento, se definen como operaciones sobre conjuntos que combinan las propiedades de traslación, la erosión y dilatación, y abarcan tanto procedimientos relativos a la extracción de características de la misma, como aquellos que se emplean antes y después de los mismos. A continuación se detallan las operaciones relacionadas a la extracción de características: 

	* Extracción de límites(boundary extraction) y componentes conectados. La extracción de limites consiste en extraer el contorno de un objeto representado en una imagen binaria, mientras que la extracción del componente conectado abarca la obtención del contorno y los pixeles que conforman la forma del objeto. Las fórmulas para estas operaciones se definen de la siguiente manera:
	  
		.. figure:: formulaExtraccionLimite.png
			:scale: 50%

			Fórmula para la extracción de borde.
		
		.. figure:: formulaComponenteConectado.png
			:scale: 50%
		
			Fórmula para la extracción de componentes conectados. Los valores Xk representan los elementos de una nueva imagen (con las mismas dimensiones que la imagen de entrada A) resultante de aplicar B sobre A.
		

	* Esqueletos(Skeletons). Un esqueleto es conjunto de elementos de una imagen que representan la forma de la misma se encuentran equidistantes a los límites.Los esqueletos en una imagen representan los objetos con el menor número de pixeles, siendo cada uno de éstos parte de la estructura básica y siendo completamente necesarios. Por lo tanto los esqueletos permiten obtener información respecto de la imagen original tales como la posición, la orientación y la longitud de los segmentos que lo conforman.
	
	El proceso para la obtención de esqueletos, consiste en aplicar una sucesión de operaciones de erosión a una imagen con un elemento ES, hasta el punto donde si se aplicara la siguiente erosión se eliminarían los objetos que pertenecen a ésta. Luego, se puede aplicar la diferencia entre las múltiples erosiones menos las múltiples erosiones aplicadas a la operación de opening, de manera que se consideren aquellos elementos no suavizados como parte del esqueleto. Finalmente, la unión de todos los esqueletos de las figuras en la imagen constituyen la imagen final. 

	 .. figure:: ejemploEsqueleto1.png
	 	:scale: 60%

		Ejemplo de la imagen binaria original 
	 |

	 .. figure:: ejemploEsqueleto2.png
		:scale: 60%
	 
		Ejemplo de la imagen luego de la obtención del esqueleto
	 
	 
	* Convex Hull. Un conjunto de elementos A se dice que es convexo si, contiene al menos dos puntos de un objeto de imagen que pueden ser vinculados por una línea recta dentro de él. Un convex hull H de un conjunto A por lo tanto, es el conjunto convexo más pequeño que contiene a A.
	  
	.. figure:: ejemploDefinicionConvexHull1.png
		:scale: 60%

		Ejemplos de convex hull convexo y no convexo. A el conjunto R1 la izquierda es convexo debido a que se puede vincular p y q, mientras que en la figura de la derecha no es convexo, sino concavo.

	|
	.. figure:: ejemploDefinicionConvexHull3.png
		:scale: 60%
	
		Ejemplo de convex hull aplicado a una imagen.
	
	El funcionamiento para la extracción del convex hull, consiste en emplear varios elementos de estructurado e iterativamente, aplicar una operación de detección de forma(shape detection) entre cada uno de los ES una imagen de entrada.Esta operación consiste en emplear la erosión entre la imagen de entrada y un ES y su complemento y el ES, con el fin de obtener resultados intermedios. De esta forma, el resultado final se obtiene uniendo cada uno de los conjuntos producto de la detección de forma. 


Las técnicas que se emplean en conjunto con la extracción de características son las siguientes:

	* Opening y Closing. La técnica de opening se emplea con el objetivo de suavizar el contorno de los objetos, eliminando conexiones entre elementos que contengan un número bajo de pixeles, y eliminando protuberancias finas. Por el contrario, closing tiende a suvizar los contornos de las figuras, pero fusiona lineas que no se encuentran completamente unidas en la figura y golfos largos y finos de pixeles, y rellena espacios en el contorno y elimina pequeños hoyos en la imagen.
	  
	.. figure:: formulaOpening.png
		:scale: 50%

		Fórmula de opening
	|
	.. figure:: formulaClosing.png
		:scale: 50%

		Fórmula de closing
	
	 
	* Thinning.Esta técnica consiste en eliminar elementos de una imagen A por medio de la aplicación de la operación de shape detection, aplicando una secuencia de n elementos de estructurado que se encuentran en diferentes ángulos. De esta forma el resultado final es una imagen donde los elementos que pertenecen a ésta han reducido su grosor y se ha ampliado la cantidad de pixeles que representan el fondo de ésta. 
 
	* Region filling. Esta operación consiste en efectuar el rellenado con información de los elementos que componen una región.
 
	* Pruning. Este método es empleado para la eliminación de elementos de imagen excedentes producto del empleo de skeletons y thinning.


* Segmentación.La segmentación de una imagen es el proceso de subdividir los pixeles en una imagen en regiones uniformes y homogéneas, donde cada región  es un grupo de pixeles, que representa un objeto o una parte de la escena que se muestra en la imagen. Así, la segmentación permite obtener agrupaciones de pixeles que comparten características similares, interconectadas y no solapadas, donde cada pixel de una región o segmento en la imagen adquiere una etiqueta de región que indica la región a la que pertenece.
Este proceso es uno de los más importantes elementos en análisis de imágenes automatizado, principalmente porque posibilita extraer aquellas entidades de interés en la imagen para aplicar otros métodos de procesamiento, como la descripción y el reconocimiento.

.. cap 6. pag. 416. Image Digital Processing. Gonzales 3rd edition.
* Procesamiento de color de imagen. Debido a que el color se considera como un descriptor potente para el reconocimiento y extracción de objetos de una escena, se han desarrollado métodos que permiten emplearlo en el procesamiento de imágenes. En general, este tipo de procesamiento consiste en trabajar con los componentes de color (o espacios de color) RGB por separado y asociar las componentes de cada uno de los pixeles de entrada para generar el pixel a color en la imagen de salida. Las tareas de procesamiento de imágenes digitales con color son variadas, aunque se distinguen las siguientes:


	*Asignación de colores basado en tonalidades de grises. Este tipo de operación s realiza con el fin de lograr un mejor entendimiento de la imagen por parte del observador. Existen diferentes aproximaciones para realizar esta tarea, destacádonse el rebanado por intensidad y la transformación intensidad-color.
	El rebanado por intensidad consiste en dividir los L-1 valores de la escala de grises en P planos, de manera que los pixeles cuyas intensidades se encuentren entre dos distintos planos sean representados por diferentes colores y, aquellos elementos que caigan en la división de un plano se le asigne el color del plano. 

	.. figure:: slicingIntensidad.png
		:scale: 50%

		Rebanado por intensidad
	
	La asignación de colores empleando transformaciones de intensidad a color se basa en aplicar tres transformaciones independientes a las intensidades para producir cada uno de los campos de color de los pixel a color de la imagen de salida, de manera que los colores de la imagen resultante, se asignan según las características del tipo de transformación que se aplique. Las transformaciones aplicables con este método pueden ser transformaciones matemáticas, o basadas en filtros de suavizado y funciones no lineales, lo que brinda flexibilidad. A continuación, se puede apreciar un ejemplo donde se aplica una transformación que produce una onda sinusoidal para cada elemento, asignando colores más intensos para los elementos cuyo valor de onda sinusoidal se encuentre con mayor inclinación:


	.. figure:: transformacionColorIntensidad1.png
		:scale: 50%

		Ejemplo de transformación intensidad a color para una imagen. La imagen de la izquierda pertenece a una maleta sin explosivos, mientras que la de la derecha pertenece a una maleta con un explosivo simulado.
	
	|

	.. figure:: transformacionColorIntensidad1.png
		:scale: 50%

		Onda sinusoidal para cada componente que representa los valores de los diferentes objetos.
	 
	Alternativamente, este procedimiento también se puede emplear aplicando transformaciones sobre varias imágenes monocromáticas de distintas bandas del espectro electromagnético (capturadas por distintos sensores) y posteriormente combinarlas en una sola, de manera que se puedan visualizar características en imágenes que complejas, que sería imposible visualizar en caso contrario. Ésta variación de la técnica se emplea en el procesamiento de imágenes multiespectrales captadas por satélites. A continuación se puede visualizar un ejemplo, donde las imágenes superior-izquierda,superior-derecha y media-izquierda se tratan como los componentes RGB para formar la imagen media-izquierda. Y la imagen inferior-derecha, se produce como resultado de combinar el campo rojo de la imagen infraroja inferior-izquierda, sobre la imagen RGB obtenida anteriormente:  


	.. figure:: imagenMultiespectral.png
		:scale: 50%
	
		Ejemplo de imagen multiespectral
	

	.. pag 448. Gonzales.
	* Transformaciones de intensidad. Las transformaciones de intensidad como el suavizado de imagen con filtros, se pueden aplicar de igual manera a los componentes de color de una imagen considerando el vector de intensidades como la entrada.
	
	* Procesamiento de Histograma. Esta tarea emplea el mecanismo de histograma de imagen y sus herramientas asociadas, aunque para procesar imágenes a color considera cada uno de los componentes de color rojo,verde y azul como un histograma separado, y emplea los niveles de intensidad de éstos para generar la imagen de salida.

	* Complementos de color. El complemento de color es equivalente al negativo en las imágenes con escala de grises, y para obtenerlo se debe modificar la tonalidad de la imagen cambiando cada uno de los componentes por su opuesto, de manera que el opuesto para un color de entrada se define en función de este por la rueda de colores que se detalle en la siguiente figura:
	
	.. figure:: ruedaComplementoColor.png
		:scale: 40%

		Ilustración de los complementos de cada color

	.. http://slideplayer.com/slide/6875110/
	.. https://www.slideshare.net/RevanthChimmani1/color-image-processing-presentation

	* Color Slicing(Rebanado por color). Esta transformación se emplea con el objetivo de separar objetos en la imagen del fondo, para ello se define un vector que representa el color neutral y posteriormente, se verifica para cada pixel si éste se encuentra dentro de un área (centrada en una coordenada de la imagen) determinada aplicando una fórmula matemática (que define la forma de ésta, si es un radio o un rectángulo por ejemplo), si es así se conserva el pixel con el color que posee. Por el contrario, si no es así se le asigna el valor del color neutral. En la siguiente figura se puede observar el efecto de esta operación sobre una imagen que contiene un bowl con frutillas:
	  

	.. figure:: colorSlicing.png
		:scale: 60%

		Color slicing ejemplos. En el ejemplo de la izquierda se empleo un cubo centrado en el punto (0,6863, 0,1608,0,1922) y en la de la derecha se empleo una esfera centrada en la misma coordenada.
	
	* Suavizado de colores(Color Smoothing). El suavizado de imagen al igual que en imágenes representadas por escala de grises, consiste en aplicar un filtro a la imagen digital de entrada con el fin producir los pixeles de salida, aunque en este las operaciones se aplican sobre los vectores que representan los componentes de color. De esta forma, la intensidad del pixel de salida se compone de procesar cada uno de los componentes de color por separado.
	  
	 
	* Segmentación por colores. Dependiendo de si el modelo de representación de la imagen es HSI o RGB se puede realizar esta operación de dos maneras diferentes: Si la imagen es HSI, la segmentación consiste en  crear una máscara binaria generada a partir de aplicar el thresholding para un valor dado, estableciendo los valores que no estan sobre ese limite a negro y conservando el resto en 1, y luego aplicarla a la imagen de saturación. La salida de este procedimiento es una imagen cuyos componentes han sido filtrados.
	  


	.. figure:: segmentacionColor.png

		Ejemplo de segmentación a color para imagen con HSI.

	Si la imagen emplea RGB, la segmentación de objetos en rangos de color específicos simplemente consiste en tomar un conjunto de puntos que cuyo color es representativo de los colores de interés, y obtener el promedio de color para cada componente y almacenar esto como un vector. Luego por medio de una fórmula de distancia, se realiza una comparación de los componentes de color de cada pixel con el vector y si se encuentra dentro de ésta distancia se lo conserva, y en caso contrario se lo descarta. La fórmula de distancia más común para realizar la medida de distancia es la Euclidiana, donde si la distancia entre el vector del pixel,z,y el vector promedio,a, se encuentra a menos de un límite,D0, se considera un color válido. 


	.. figure:: formulaDistanciaEcludiana.png
		:scale: 50%
		Fórmula de distancia Euclidiana


* Representación y descripción. Este proceso mayormente se emplea a continuación del proceso de segmentación, ya que ésta produce datos relacionados con los pixeles contenidos en el límite o en la región y es preferible emplear esquemas que compacten la información segmentada para mejorar el procesamiento de descriptores.
Estas técnicas, consisten en transformar los pixeles que forman una región en una representación conveniente para su procesamiento. La representación de una región proporciona dos alternativas: Representar la región en términos de sus características externas (su límite o boundary por ejemplo), describiéndose el limite por sus características como su longitud, la orientación de la línea recta que conecta sus puntos extremos, y el número de concavidades en el límite;
O representarla según sus características internas, es decir, los pixeles que comprenden la región. En este caso, se emplean características propias de la región tales como el color y la textura. La característica principal de la textura, es que consiste en la repetición de un patrón o conjunto de patrones sobre una región. Éste puede ser repetido exactamente o con pequeñas variaciones de posición y, ciertas características como: forma, tamaño, color y orientación de los elementos que forman el patrón pueden variar sobre la región.Algunas veces, la diferencia entre texturas se obtiene por medio del grado de variación de los mismos o, en la distribución estadística de los elementos del patrón.
Con respecto a la descripción de una textura, existen 3 aproximaciones para esta tarea: 
	
	* La aproximación estadística. La aproximación estadística consiste en emplear medidas cuantitativas estadísticas(media aritmética, varianza, desvío estándar y otras) respecto a la distribución de los niveles de intensidad a una imagen, asociando distintas combinaciones de estos valores a características a tales como la suavidad, la aspereza, la granularidad, etc.; Y descriptores que, en base una operación que define relaciones entre pixeles y las frecuencias de esas relaciones entre pixeles en la imagen, organizados en forma de matriz de N x N siendo N los niveles de intensidad(matriz de co-ocurrencias), permiten encontrar y describir patrones tales como la uniformidad, homogeneidad, contraste y correlación. 
	  
	  .. figure:: ejemploMatrizCoOcurrencias.png
	  	:scale: 50%
	  
		Ejemplo de matriz de co-ocurrencias(derecha) de una imagen (izquierda),para 8 niveles de intensidad, definiendo la relación entre pixeles como aquel pixel que se encuentra inmediatamente a la derecha. 
	  
	  

	* La aproximación estructural. Esta técnica consiste en describir una textura por medio de un conjunto de reglas(o primitivas) que representan el patrón de la misma, que se repite de manera constante.
	
	* La aproximación espectral. Esta aproximación se basa en las propiedades de la  transformada de Fourier, y son usadas primariamente para detectar periodicidad en la totalidad de la imagen a través de picos en el espectro de las frecuencias de la imagen. 

|

.. figure:: ejemplosTexturas.png

	Ejemplos de texturas artificiales (a-b) y texturas naturales(c-e)


Estudios relativos a la detección de fallas
"""""""""""""""""""""""""""""""""""""""""""

En lo que respecta al procesamiento de imágenes, una de las aproximaciones que se han empleado dentro de esta área es la de Koch y Brikalis :cite:`antecedentesProcImg1`, que se centra en el reconocimiento de hoyos en el pavimento por medio de una variedad de imágenes provenientes de distintas fuentes (tomadas manualmente, Google o capturas de videos con calles), tomadas desde una distancia menor al metro del suelo y en distintos ángulos. En este estudio se emplea un modelo que utiliza las sombras en las imágenes para detectar la ubicación del hoyo dentro del pavimento, y posteriormente aislarlo de éste. Este modelo consiste de 3 fases: Segmentación de la imagen, extracción de forma y comparación de texturas. 

Durante la segmentación de la imagen, se realiza la conversión de la imagen desde el modelo de color RGB a una escala de grises, se obtiene el histograma de imagen y se aplica la técnica de limitado de imagen para un valor, y se la convierte a una imagen binaria. Luego, en la etapa de extracción de forma se procede a aplicar thinning hasta obtener el esqueleto de imagen y a conectar las ramificaciones empleando un algoritmo de regresión elíptica,debido a que el ángulo de captura de las imágenes no es perpendicular al suelo. En este estudio, se definieron parámetros para determinar el grado de curvatura de los elementos en la imagen (eccentricity o e, donde cuando más próximo a 0 es e, mayor es su curvatura), la posición del centroide (centro de gravedad de la imagen, que representa la posición promedio de todos los puntos en un plano) y el tamaño de la región. De esta manera, por medio de estos parámetros obtenidos experimentalmente se clasificaron las regiones en cada imagen como candidatas a un hoyo o, como una región externa al mismo. 

Finalmente, en la fase de comparación de texturas se caracterizan las mismas por medio de la aproximación estadística, y se emplea un vector de características que se genera con una serie de filtros para cada región interna y externa y, finalmente estas se comparan empleando un mecanismo de machine learning de MATLAB, en combinación con el set de herramientas de procesamiento de imágenes integrados. De esta forma, el entrenamiento se realizó con 50 muestras de imágenes seleccionadas aleatoriamente, y la prueba fue llevada a cabo con 70 muestras, que contenían no solo hoyos, sino también elementos típicos que se pueden encontrar en caminos pavimentados, como son grietas,reparaciones y juntas. El resultado de este estudio fue favorable, ya que se lograron valores de precisión cercanos al 80%, sin embargo, este modelo tiene la desventaja de depender fuertemente de condiciones de luz solar óptimas,por la naturaleza de su funcionamiento. Además, si el angulo del sol con respecto al suelo es perpendicular, la cantidad de sombra generada en la imagen es mínima por lo que algunos baches pueden pasar inadvertidos.


.. figure:: modeloBrikalis.png
	:scale: 60%

	Modelo de procesamiento propuesto por Brikalis y Koch.Figura extaída desde :cite:`antecedentesProcImg2`.


Posteriormente, la aproximación de Koch y Brikalis definida en :cite:`antecedentesProcImg2` se extendió para incluir el procesamiento de frames de video, debido a que en el estudio anterior el procesamiento completo se debe aplicar a cada imagen individual, lo que resulta computacionalmente ineficiente, ya que el bache tiene que ser detectado sucesivamente dentro de cada cuadro de video. Con este método, empleando las características de la textura en un bache, la forma elíptica y la sombra que se forma alrededor de ésta, el procesamiento consiste en subdividir la región de obtención de texturas a un área central con una cierta cantidad de pixeles, y aplicar filtros a cada una de las regiones, con el fin de obtener vectores de características para cada región. Este procedimiento se emplea en el primer frame sobre un área de pavimento no dañada, obteniendo así un valor de vector de características para un sector intacto. Después, a medida que se obtienen los subsecuentes frames se compara el promedio de los vectores de características anterior con el nuevo promedio, si no existe una diferencia significativa se actualiza y en caso contrario se produce la detección de un hoyo. Adicionalmente, este método, una vez que detecta un bache procede a detener el algoritmo de comparación de texturas, e inicia un algoritmo de tracking de objetos basado en valores de texturas para efectuar el seguimiento de éste, hasta que ya no figura en la imagen. En este punto, se procede a reanudar el algoritmo de detección de fallas hasta detectar un nuevo bache en el pavimento.
Este experimento, fue testeado capturando el video desde un robot equipado con una cámara, con un total de 39 videos (10180 frames), logrando una precisión del 75% y un recall 84%(ver machine learning). Sin embargo, esta aproximación tiene el inconveniente de que unicamente se considera que solamente un único hoyo entrará en el campo de visión a la vez.


.. figure:: brilakisMejora.png
   :scale: 60%

   Método anterior de Brikalis y Korch, con mejoras subrayadas.Figura extaída desde :cite:`antecedentesProcImg2`.



.. VER PAPER 2012,2013,2015. 
.. https://en.wikipedia.org/wiki/Similarity_measure

Otra aproximación que se ha empleado para la detección de fallas, es la expuesta por Buza, Omanovic y Huseinovic en :cite:`antecedentesProcImg3`, que consiste en realizar la obtención de imagenes o frames de video a partir de grabaciones realizadas con cámaras digitales montadas exteriormente a vehículos. El primer paso en esta aproximación consiste en transformar la imagen a color (en RGB) a escala de grises, para luego continuar con la segmentación de la imagen a través del thresholding (o limitado) de los valores en el histograma de imagen. Así, el límite de la imagen se calcula por medio del método de Otsu para el clustering en imágenes, que consiste en aplicar una fórmula matemática (ecuación (2) de :cite:`antecedentesProcImg3`) que realiza la división entre los valores de intensidad del histograma de manera que, se realice la división entre los pixeles del fondo y de los objetos, obteniendo una variación mínima de intensidad dentro de los elementos que componen cada una de estas clases y una variación considerable entre elementos de distintas clases. Luego, se extraen aquellas formas de la imagen que son lineales, por medio del valor de curvatura (eccentricity) y aquellas formas en la imagen que se encuentran conectadas al límite de ésta. Como salida, se obtiene una imagen intermedia con formas lineales, figuras conectadas al borde la imagen y que no satisfacen el límite de Otsu removidas.  


.. DEFINIR EIGEN VALUES Y EIGEN VECTORS!!
Posteriormente, se procede a realizar la extracción de forma aplicando un algoritmo de clustering, donde se realiza la agrupación de los elementos en k clusters (definidos por el usuario) según su similitud en conjuntos o clusters de pixeles. El método seleccionado fue el Spectral Clustering, que se basa en aceptar como entrada una matriz de similitud, donde cada uno de los elementos (i,j) de ésta representa el grado de similitud de los puntos i y j, empleando para medir éste una fórmula de distancia Euclidiana normalizada por un factor de escala (ecuación (4) de :cite:`antecedentesProcImg3`). El factor de escala se calcula en base a los valores del histograma de imagen(ecuación 5 de :cite:`antecedentesProcImg3`). El funcionamiento de este método consiste en realizar una reducción de dimensionalidad, computando los eigen valores en la matriz de similitud, para luego realizar el clustering con menos dimensiones.

El próximo paso consiste en seleccionar de la imagen intermedia un conjunto de "semillas" o puntos, tales que cada uno de esos puntos se emplea como una representación de otros 50 puntos para el próximo paso; Ésto se realiza con el fin de reducir el tiempo de cómputo. Estas semillas se emplean para la extracción de la región del bache vertical, donde se considera cada una de éstas eligiendo aquellas cuyas coordenadas tengan el valor mayor y menor en Y y por medio de la inspección de la imagen clusterizada, se procede a seleccionar los pixeles cuyos valores de intensidad sean mas proximos al valor de la semilla, obtieniendo así la región vertical del bache. El procedimiento anterior, se realiza de manera análoga para definir una región horizontal del hoyo, a excepción de que se seleccionan las semillas que tienen una coordenada con valor X mayor y menor (dentro del conjunto de las semillas), seleccionando aquellos pixeles más a la derecha y mas a la izquierda. Como pas final, se procede a unir los pixeles que componen la región del bache con líneas a fin de identificar su área y posición en la imagen. Este método fue testeado en MATLAB con la suit de imagenes integrada, con 50 imagenes seleccionadas de Google, donde 25 imágenes son hoyos, 10 grietas y el resto imagenes con reparaciones y areas sin defectos, lográndose una precisión del 80%.

.. figure:: procesoIdentificacionPotholes.png

   Proceso de extracción de potholes. Extraído desde :cite:`antecedentesProcImg3`.


En otros estudios como :cite:`antecedentesProcImg4`,se especifica un sistema inteligente de transporte(ITS) para la advertencia de fallas, donde se integran métodos deterministas para el recononcimiento y ponderación de la gravedad de los baches, basados en su localización y características. Este sistema consiste en en emplear un vehículo con dipsotivo de sensado estacionario, que agrupa elementos tales como: una cámara de video digital CCD, GPS para la obtención de la ubicación, espacio de almacenamiento para las capturas, y comunicación Wi-Fi. Este dispositivo permite obtener muestras del pavimento que son enviadas a un algoritmo de detección de baches para análisis, y en caso de detectar una falla, se estima su criticidad por medio de un valor establecido y ésta junto con su ubicación puede ser enviada por medio de dispositivos ubicados al costado del camino, a un sistema para la administración de fallas por medio de Comunicaicón de corto Rango Dedicada(DSRC), WAVE o Wi-Fi. Así, cuando otro vehículo que emplee el mismo sistema circule cerca de la misma zona, el conductor puede ser advertido acerca de una falla.


.. figure:: antecedenteSistemaDeteccionFallas.png

   Sistema propuesto para la detección de fallas. Extraído desde :cite:`antecedentesProcImg4`.


Con respecto al método de detección de hoyos en imágenes, el primer paso consiste segmentar la imagen aplicando para ésto el limitado de histograma basado en forma(HST,Histogram Shape-based thresholding) lo que produce una imagen binaria con las regiones segmentadas, y luego aplicar un filtro 9x9 a la imagen para reducir el ruido y la operación morfológica de closing, lo que permite eliminar el ruido producido por la segmentación y cerrar las regiones candidatas. A continuación, se computan las características para la selección de regiones candidatas, tales como: la linearidad, el tamaño, el nivel de compactación (definida en base al area y el perímetro de la región), la elipcidad, los centroides y el convex hull y se definen límites para éstos de manera de filtrar solo aquelals regiones que cumplan con éstos requisitos. Posteriormente, se aplica la técnica de intersección de histograma ordenado (OHI), cuya ecuación se encuentra definida en (4) de :cite:`antecedentesProcImg4`, donde se computa un valor producto de la comparación de los mínimos valores de histograma entre el histograma de una región candidata y el fondo de la imagen. Finalmente, si el desvío estándar entre ambos histogramas (region y fondo) es inferior a un valor límite, o si el valor de OHI es cercano a 1 y aplicando la operación de Sobel (operador para el la detección de bordes que computa la pendiente de la función de intensidad de la imagen) es cercano a 1, se considera que la región candidata y el fondo son parte de la misma superficie, por lo que la región no es hoyo. Las pruebas para este método se realizaron con la cámara del dispositivo de captura en Korea, implementando el algoritmo de selección de regiones en C++, capturando un total de 90 imagenes en 100 experimentos, logrando valor de accuracy de 73%, con una precisión del 80% y 73.3% de recall.


Otras investigaciones plantean un método mas directo, sin emplear machine learning o clasificación  para el procesamiento de baches, como en :cite:`antecedentesProcImg6` donde se creó una librería de imágenes empleando un vehículo con una cámara GoPro montada en el parabrisas y extrayendo frames de estas filmaciones. En esta metodología no se consideran otros elementos del camino como vehículos, arbustos o árboles al costado del camino, por lo que con cada imagen se calcula el desvío estandar de los canales de de color de la imagen, se filtran aquellos elementos que se encuentran en el rango de valores del color del asfalto (justo en frente del vehículo) y, se obtiene el convex hull del camino, para obtener una forma uniforme. Una vez aislado el camino, se convirte la imagen de color a escala de grises, se remueve el ruido aplicado una técnica de filtrado Gaussiano, y finalmente, se aplica el algoritmo de Canny (empleado para la detección de bordes en imágenes) que produce una imagen binaria, y se refina la imagen con el método de dilatación para eliminar contornos sobrantes producto de éste algoritmo. Este experimento se implementó en Visual C++ con OpenCV, empleando 53 imagenes en total con 97 fallas de la librería bajo distintos escenarios, a una velocidad de 40 km/h, logrando una precisión de 81.8% y un recall 74.4%. No obstante, este algoritmo tiene el inconveniente de que los baches que se encuentran en el borde del campo de visión del vehículo son mayormente ignorados por el algoritmo de Canny, y que ciertos tipos de bordes en el campo de visión del vehículo no son captados debido a la rigidez de el algoritmo de detección de bordes.   


.. figure:: ejemploAntecedenteAlgoritCanny.png

   Ejemplo de los pasos realizados en el método propuesto. Extraído de :cite:`antecedentesProcImg6`.


Además de baches, también se han efectuado estudios donde se intentan aislar del pavimento como :cite:`antecedentesProcImg5`,donde la métodología elegida consiste en realizar un pre-procesamiento de la imagen, escalando ésta a una resolución pre establecida y aplicando una normalización de los valores de intensidad de la imagen y realizando una saturación de pixeles (donde se ajustan los valores de pixeles para que no superen un determinado límite). Luego, se subdivide la imagen en bloques de imagen no solapados y se generan las características de cada bloque, considerando solamente el desvío estandar y la media aritmética, y se aplica el algoritmo de K-Means para estas características. Así, la matriz de desvío estandar de cada uno de los bloques de la imagen de entrada, se resta contra una matriz de desvíos estándar perteneciente a una imagen con pavimento sano, y si la diferencia entre ámbos es significativa se este bloque se guarda en una imagen binaria nueva con cada uno de sus valores en 1(blanco), en caso contrario se le asigna 0 (negro).Finalizado el procedimiento anterior, se procede a asignar un nivel de severidad a la grieta calculando se realiza el thresholding con el método de Otsu a la imagen de entrada, seleccionando como límite el menor valor del limite de Otsu para el asfalto sano y la imagen con la grieta, obteniendo como salida el componente conectado. Luego la forma de la grieta se aproxima obteniendo el esqueleto, y eliminando los valores sobrantes con region opening. Por último, se calcula el grosor la grieta como el numero total de pixeles en una grieta dividido por el número de pixeles en el esqueleto de la grieta. 

.. NOTA: VER EL PAPER DE PROCESAMIENTO  DE IMAGENES HYPERESPECTRALES...
.. NOTA: PONER 2 PAPERS PARA TRATAMIENTO DE GRIETAS

Alternativamente a este estudio, otra aproximación  definida en :cite:`antecedentesProcImg7` propone emplear los niveles de intensidad de una imagen en escala de grises(256 niveles) para detectar la diferencia entre la grieta y el fondo, teniendo en consideración que la forma de la grieta es fina y que, existe una diferencia considerable de intensidades entre ésta y el resto de la imagen. Esta técnica consiste en aplicar una máscara de filtrado (o ventana) que cuenta con un tamaño inicial y un tamaño final, variable a medida que se aplica ésta sobre la imagen. De esta forma, al realizar el proceso de filtrado se aceptan aquellos pixeles cuyas intensidades sean menores que un valor límite T establecido, actualizandose el límite para valores que lo superan, y al alcanzar una cantidad maxima de pixeles para la región candidata filtrada, el valor de la máscara se incrementa. Este procedimiento se repite hasta alcanzar el tamaño máximo de la máscara. 

Adicionalmente, a medida que la máscara se aplica sobre la imagen, se calcula un valor de circularidad Fc a través de una fórmula matemática (definido en (2) en :cite:`antecedentesProcImg7`) en base a la cantidad de pixeles filtrados en la zona actual de la imagen (que cuanto más próximo a 1 este indicará que la grieta tiende en mayor medida a ser una elipse). Este valor, en combinación con un parámetro de acelaración (definido en ecuación (3) y (1') en :cite:`antecedentesProcImg7`), cuyo valor inicial es un parámetro de entrada, se emplea para modificar la rapidez con que se modifica el valor T de intensidad, de manera que si la grieta es fina y delgada, el valor T se modifica más lentamente captando con más detalle la grieta, mientras que si por el contrario tiende a otro tipo de forma la velocidad de actualización es constante. También se agrega otra modificación en este estudio para en lugar de emplear un tamaño minimo y máximo de ventana, se emplee longitud de la grieta mínima y máxima (especificados por el usuario) y se la compara con un valor de circularidad Cmax para aumentarlo, solamente si se supera ese valor. Este estudio fue probado con 114 imágenes capturadas con camaras digitales, brindando un recall de 0.753 y precision de 0.788, lo que lo convierte en un método apropiado para la clasificación de grietas.


Proyectos basados en sensores de vibración
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. PROYECTO "BUSNET" Y "POTHOLE PATROL" que emplean GPS con sensores de vibración.

Una de las investigaciones que hace empleo de acelerómetros es la de Eriksson,Girod,Hull,Newton,Madden y Balakrishnan :cite:`antecedentesProcImg8` donde se diseña un sistema para la detección de baches que captura elementos en el camino (pudiendo ser éstos:cruces de peatón, ), determina la localización del mismo con GPS y envía estos datos a un servidor para clasificación. De esta forma, la arquitectura general del sistema consiste en 3 módulos: El módulo de sensado, el módulo de detección de baches y el módulo de clasificación;
El primer módulo, se compone por 3 acelerómetros 380-Hz que sensan en tres ejes X,Y,Z, ubicados 2 en la parte delantera y uno en la parte trasera de la cabina del vehículo, de manera que las mediciones se capturen por éstos 3 y se reduzca la posibilidad de detectar incorrectamente un cierre de puertas, frenada brusca del chofer, el paso por puentes (entre otras) como un hoyo. De ésta manera, cuando en el recorrido por un sendero vial se atraviesa un bache, se capturan los abruptos cambios de energía entre los ejes X y Z, la fecha y la aceleración, que posteriormente son enviados directamente al módulo de sensado. Este módulo, divide cada uno de los streams de información de los 3 ejes con las vibraciones, en 256 muestras o windows, y posteriormente aplica una serie de filtros (definidos en la sección :cite:`antecedentesProcImg8`) a cada uno de éstas muestras por medio de la aplicación de una fórmula matemática que hace uso de un valor límite "t", que permite regular la tolerancia de éstos para considerar algo como bache o no. Estos filtros permiten filtrar sólo aquellos frames que cumplan las características de interés tales como: frames donde existan diferencias de energía en los sensores pero el vehículo se encuentre en marcha, o aquellas muestras donde la variación sea mímina (de acuerdo con el límite fijado para el filtro). Para este estudio, estos filtros se calibraron a través de varias pruebas para asignar un valor t a cada uno de los filtros, de manera que se maximice la precisión en la detección de baches.

Posteriormente, los datos filtrados junto con la fecha y la localización obtenida por GPS, cuando se tiene una conexión de interner disponible, pueden ser enviados a través de una red Wifi abierta o, de la red de paquetes de datos de una compañía celular, al servidor central. En este servidor se mantiene una base de datos de las detecciones, realiza un clustering de las muestras enviadas, considerando que solamente K eventos pueden ocurrir en una localización dada mientras el vehículo se mueve en una dirección, de manera que se restringan por esta frecuencia de ocurrencias aquellos eventos que no son fallas (tales como la vibración dentro del vehículo en movimiento).

.. figure:: arquitecturaAntecSensor.png

   Arquitectura propuesta por Eriksson,Girod,Hull,Newton,Madden y Balakrishnan. Extraído desde :cite:`antecedentesProcImg8`.

En este estudio, se entrenaron los filtros por medio de muestras tomadas manualmente (donde se registraba el tipo de evento que produce la variación en el acelerómetro, además de su fecha y posición) y algunos datos semi-automáticos (sólo contienen las variaciones del sensor de vibración, sin especificar ubicación o fecha) evaluando los valores para t que brindan el mayor valor en la fórmula, para despues validar este algoritmo con otro conjunto de datos recolectados de manera semi-automática. Los resultados obtenidos fueron satisfactorios, aunque este método tiene el defecto de detectar algunos elementos (como bocas de tormenta) que producen variaciones similares a baches como baches, y que para esta técnica funcione las ruedas del vehículo deben circular sobre el bache, por lo que si éste se ubica entre medio de las ruedas, no es sensado.

.. MOMENTO ESTADISTICO -->
.. https://es.wikibooks.org/wiki/Apuntes_matem%C3%A1ticos/Estad%C3%ADstica/Cap%C3%ADtulo_3/Momentos

.. PAPERS TENTATIVOS:
..                   -2011, Mednis, Strazdins,Zviedris "Real time pothole detection using Android" (No USADO)
..                   -2011, "Road Condition monitoring using on-board three-axis acelerometer"
..                   -2013, "Assessment of vehicular transportation quality via smartphones"
    
..                   -2014, "Detection and localization of potholes in roadways using smartphones"

..                   -2016, "Pothole detection through IoT" y "Automatic detection of Potholes and Humps on Roads to aid drivers",("Pothole detection and inter vehicular communication(2014)") son exprimentos con sensores ultrasonicos.

En otros estudios como :cite:`antecedentesProcImg9` se han centrado en clasificar los baches según distintas métricas obtenidas a partir de las mediciones de un sensor acelerómetro, siguiendo algún estándar. En este sistema, se emplea un acelerómetro MEMS (dispositivo microscópico con partes mecanicas desplazables) modelo LIS33DE  en combinación con un GPS para capturar la aceleración de los hoyos y, estos valores son limpiados eliminando datos de encendido del sensor, aplicando interpolación para obtener los datos de aceleración faltantes y se remueven aquellos valores extremos que superan un cierto límite. La información  saneada de los ejes X,Y,Z, junto con la velocidad, la fecha y la ubicación se suben a un servidor central donde se calculan el Índice de Calidad de Circulación (RQI) (en base al desvío estandar de una métrica para medir el nivel de aspereza del pavimento calculada empleando la Transformada de Fourier) y en base a éste y a la velocidad estimada, se asigna un nivel de aspereza al pavimento según el código técnico de mantenimiento CJJ36 empleado en la República China. Para el expermiento se emplearon varios acelerómetros, ubicados de manera fija en la cabina del conductor, colocando el eje X para que concida con dirección en que se maneja, correspondiendo el eje Z a la dirección vertical y el eje Y a la horizontal (respecto al suelo), a lo largo de distintos tipos de caminos, obteniendo medidas sin variaciones de aspereza bruscas en caminos suaves y, fluctuaciones considerables en al circular por caminos con fallas viales. 

.. http://www.gsmarena.com/glossary.php3?term=sensors

.. TODO: COMPLETAR ESTE PARRAFO!!!

Sin embargo, con el avance de la tecnología móvil se han efectuado estudios como :cite:`antecedentesProcImg10` y :cite:`antecedentesProcImg11` que hacen uso de un acelerómetro embebido en dispositivos Android, en combinación con otros sensores en éste, para el sensado de hoyos sobre el pavimento. En :cite:`antecedentesProcImg10`, se emplean no solo los datos del acelerómetro, sino también del giróscopo y del compas digital. En esta aproximación, se realizó un análisis de las características que proporcionarían mayor precisión donde se  emplearon dos aplicaciones existentes para los dispositivos Android: "Sensor Logger" que permite obtener los datos de los tres sensores y "Event Timestamper" que permite registrar la fecha y hora de ocurrencia de los eventos con el fin asignar un label a cada uno de los eventos capturados. Posteriormente, se les aplico un filtro a las muestras para acotar el rango de frecuencias y, para reducir el uso de memoria, se realizó la suma de la información vectorial de los sensores para la extracción de features. Luego, durante la extracción de características se empleo el framework para la extracción de features de señales de una dimensión jAudio, se seleccionaron las características con mayor grado de correlación y, se probaron varios modelos de clasificación de Machine Learning de la herramienta WEKA seleccionando una red neuronal Bayesiana. Durante la selección del modelo Machine Learning, se realizaron distintas pruebas y se agruparon los eventos de ciruclación en distintas clases entre las que se encuentran: Eventos de Caminos, eventos de conducción(aquellos relativos al giro en ambas direcciones o frenadas ), movimiento del celular o conducción suave. 

Finalmente, durante la etapa de prueba se ejecutó la aplicación de logging de eventos y el algoritmo de clasificación en el dispositivo y, en lugar de emplear un timestamping, se dividió la señal del sensor en segmentos o ventanas de 5 segundos,  realizando la clasificación tan pronto como el tiempo de la ventana se complete. De esta forma, se adquirieron 1196 ventanas para testeo, y los resultados se superponieron sobre el video del recorrido captado por una cámara de video, produciendo como resultado final la grabación que marca los instantes en los que se circula por un bache. La precisión obtenidas este método fue de 86% con muestras reales.


Mientras que el sistema RSMS(Roadway State Monitoring System) de información geográfica (GIS) en :cite:`antecedentesProcImg11` se empleó una aplicación local en el dispositivo para la captura de datos, programada en Java con Android SDK, que se comunica por medio del estándar SOAP (empleando XML) con una aplicación web.  En este sistema, el dipositivo de captura se encuentra colocado de forma horizontal sobre el suelo para que el eje Y del acelerómetro coincida con el sentido circulación, siendo el eje Z perpendicular a éste. Los datos sensados durante la captura, son leídos por la aplicación local en Java, la cual aplica un filtro para reducir el ruido en la señal y, junto con la información provista por un GPS(localización, velocidad,latitud y longitud) y la información relativa al compás digital del dispositivo (grados azimuth que miden la orientación del dispotivo) se envían al servidor web, por medio de una conexión Wifi si esta disponible o una red GPRS.

El servidor al recibir esta información, realiza el cálculo del valor VIZIR (:cite:`antecedentesProcImg101`) que asigna un índice a la muestra,con el fin de estimar el daño en la superficie del pavimento y asignarle una categoría a los valores en la escala de éste. Una vez clasificada la muestra, se registra en una base de datos local en MySql, y se emplea la API de Google Maps (servidor LBS ) para indicar la ubicación de las fallas en un mapa y, además se añade funcionalidad para filtrado de fallas por fecha y por estación.


.. figure:: arquitecturaRSMS.png
   :scale: 50%  

   Arquitectura del sistema propuesto. Extraído desde :cite:`antecedentesProcImg11`.
     


Proyectos basados en el uso de reconstrucción 3D
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


AGREGAR INFO DE 2 O 3 PAPERS




Aplicaciones web y móviles existentes para la notificación de fallas
--------------------------------------------------------------------

.. ACA INCLUIR LOS SISTEMAS WEB EN "Ejemplos de otros sistemas para el registro de fallas.txt"


